{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c921bc9-7571-48c4-950e-d35e94c9827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "from annnet.core.graph import AnnNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff7d962-eded-4e20-bf74-5ffb2d156572",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Composite indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50634fb-2774-41bf-8fea-7b4ec35b58d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G = AnnNet()\n",
    "\n",
    "G.set_vertex_key(\"name\", \"sex\")\n",
    "\n",
    "m = G.get_or_create_vertex_by_attrs(name=\"a\", sex=\"man\")\n",
    "w = G.get_or_create_vertex_by_attrs(name=\"a\", sex=\"woman\")\n",
    "\n",
    "print(m, w, m == w)   # expect two different ids, False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4023de80-8559-4bf1-bb6c-b76d5b2d0029",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.set_vertex_key(\"name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a5fc81-cd05-40c6-b3c7-a7a341353bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = G.get_or_create_vertex_by_attrs(name=\"a\", sex=\"man\")\n",
    "w = G.get_or_create_vertex_by_attrs(name=\"a\", sex=\"woman\")\n",
    "print(m, w, m == w)   # same id, True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22761a4-78d8-4d3c-85be-8c12937f5a17",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Flexible directionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f32450-bf5d-4a11-8aca-014a84c1c81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = AnnNet()\n",
    "G.set_vertex_key(\"name\",\"sex\")\n",
    "\n",
    "u = G.get_or_create_vertex_by_attrs(name=\"a\", sex=\"man\")\n",
    "v = G.get_or_create_vertex_by_attrs(name=\"a\", sex=\"woman\")\n",
    "\n",
    "# Helper to read signs\n",
    "def signs(G, eid):\n",
    "    s,t,_ = G.edge_definitions[eid]\n",
    "    col = G.edge_to_idx[eid]\n",
    "    si = G.entity_to_idx[s]; ti = G.entity_to_idx[t]\n",
    "    M = G._matrix\n",
    "    return M.get((si,col),0), M.get((ti,col),0)\n",
    "\n",
    "# Edge-scope policy\n",
    "e = G.add_edge(u, v,\n",
    "    flexible={\"var\":\"capacity\", \"threshold\":0.7, \"scope\":\"edge\", \"above\":\"s->t\", \"tie\": \"undirected\"},\n",
    "    capacity=0.5, weight=1.0)\n",
    "\n",
    "print(\"init:\", signs(G,e))            # expect (-1, +1)\n",
    "G.set_edge_attrs(e, capacity=0.9)\n",
    "print(\"after:\", signs(G,e))           # expect (+1, -1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43797504-2272-4255-8e32-bd2ed063906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertex-scope policy\n",
    "G2 = AnnNet()\n",
    "G2.set_vertex_key(\"name\",\"sex\")\n",
    "s = G2.get_or_create_vertex_by_attrs(name=\"a\", sex=\"man\")\n",
    "t = G2.get_or_create_vertex_by_attrs(name=\"a\", sex=\"woman\")\n",
    "G2.set_vertex_attrs(s, temp=10.0)\n",
    "G2.set_vertex_attrs(t, temp=20.0)\n",
    "\n",
    "e2 = G2.add_edge(s, t,\n",
    "    flexible={\"var\":\"temp\",\"threshold\":0.0,\"scope\":\"vertex\",\"above\":\"s->t\",\"tie\":\"undirected\"},\n",
    "    weight=1.0)\n",
    "\n",
    "print(\"xs<xt:\", signs(G2,e2))         # (-1, +1)\n",
    "G2.set_vertex_attrs(s, temp=25.0)\n",
    "print(\"xs>xt:\", signs(G2,e2))         # (+1, -1)\n",
    "G2.set_vertex_attrs(t, temp=25.0)\n",
    "print(\"tie  :\", signs(G2,e2))         # since \"tie\":\"undirected\", it becomes: (+1, +1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb16a2e-a187-43ce-8c3f-a7aeff768ddd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Kivela Multilayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df9e99b-c492-4672-b83d-0566a4890cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- build a tiny Kivela multilayer graph ----------\n",
    "\n",
    "G = AnnNet(directed=True)\n",
    "\n",
    "# 1) Define aspects and elementary layers\n",
    "G.set_aspects(\n",
    "    aspects=[\"time\"],\n",
    "    elem_layers={\"time\": [\"t1\", \"t2\"]},\n",
    ")\n",
    "\n",
    "# 2) Add vertices in the base graph\n",
    "for u in [\"A\", \"B\", \"C\"]:\n",
    "    G.add_vertex(u, name = f\"named {u}\")\n",
    "\n",
    "# 3) Declare vertex-layer presence (V_M)\n",
    "for u in [\"A\", \"B\", \"C\"]:\n",
    "    G.add_presence(u, (\"t1\",))\n",
    "    G.add_presence(u, (\"t2\",))\n",
    "\n",
    "# 4) Add Kivela edges (all go through incidence under the hood)\n",
    "\n",
    "# intra edges in t1\n",
    "G.add_intra_edge_nl(\"A\", \"B\", (\"t1\",), weight=1.0)\n",
    "G.add_intra_edge_nl(\"B\", \"C\", (\"t1\",), weight=1.0)\n",
    "\n",
    "# intra edges in t2\n",
    "G.add_intra_edge_nl(\"A\", \"C\", (\"t2\",), weight=2.0)\n",
    "\n",
    "# inter-layer edge between A@t1 and B@t2\n",
    "G.add_inter_edge_nl(\"A\", (\"t1\",), \"B\", (\"t2\",), weight=0.5)\n",
    "\n",
    "# coupling edges A: t1 <-> t2 and B: t1 <-> t2\n",
    "G.add_coupling_edge_nl(\"A\", (\"t1\",), (\"t2\",), weight=1.0)\n",
    "G.add_coupling_edge_nl(\"B\", (\"t1\",), (\"t2\",), weight=1.0)\n",
    "\n",
    "# ---------- annotate layers and vertex-layer pairs ----------\n",
    "\n",
    "# Elementary layer attributes, stored in G.layer_attributes\n",
    "G.set_elementary_layer_attrs(\"time\", \"t1\", order=1, name=\"early\")\n",
    "G.set_elementary_layer_attrs(\"time\", \"t2\", order=2, name=\"late\")\n",
    "\n",
    "# vertex-layer attributes, stored in _vertex_layer_attrs\n",
    "G.set_vertex_layer_attrs(\"A\", (\"t1\",), activity=0.2, color=\"blue\")\n",
    "G.set_vertex_layer_attrs(\"A\", (\"t2\",), activity=0.9, color=\"red\")\n",
    "G.set_vertex_layer_attrs(\"B\", (\"t1\",), activity=0.5)\n",
    "G.set_vertex_layer_attrs(\"B\", (\"t2\",), activity=0.7)\n",
    "\n",
    "print(\"vertex-layer attrs A@t1:\", G.get_vertex_layer_attrs(\"A\", (\"t1\",)))\n",
    "print(\"vertex-layer attrs A@t2:\", G.get_vertex_layer_attrs(\"A\", (\"t2\",)))\n",
    "print()\n",
    "\n",
    "# ---------- supra structures ----------\n",
    "\n",
    "A_supra = G.supra_adjacency()\n",
    "print(\"Supra adjacency shape:\", A_supra.shape)\n",
    "print(\"Supra adjacency matrix:\\n\", A_supra.toarray())\n",
    "print()\n",
    "\n",
    "L_comb = G.supra_laplacian(kind=\"comb\")\n",
    "L_norm = G.supra_laplacian(kind=\"norm\")\n",
    "print(\"Combinatorial Laplacian:\\n\", L_comb.toarray())\n",
    "print()\n",
    "print(\"Normalized Laplacian:\\n\", L_norm.toarray())\n",
    "print()\n",
    "\n",
    "print(\"vertex-layer index (row -> (vertex, layer_tuple)):\")\n",
    "for i, (u, aa) in enumerate(G._row_to_nl):\n",
    "    print(f\"  {i}: {u} @ {aa}\")\n",
    "print()\n",
    "\n",
    "deg = G.supra_degree()\n",
    "print(\"Supra degrees per vertex-layer row:\", deg)\n",
    "print()\n",
    "\n",
    "print(\"Participation coefficient per vertex:\", G.participation_coefficient())\n",
    "print(\"Versatility per vertex:\", G.versatility())\n",
    "print()\n",
    "\n",
    "print(\"Layer attribute table (Polars):\")\n",
    "print(G.layer_attributes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea871cc-bf9d-4855-8182-56d66df59414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Kivela layer algebra & slice operations ----------\n",
    "\n",
    "aa_t1 = (\"t1\",)\n",
    "aa_t2 = (\"t2\",)\n",
    "\n",
    "print(\"\\n=== Kivela layer vertex/edge sets ===\")\n",
    "print(\"Vertices in layer t1:\", G.layer_vertex_set(aa_t1))\n",
    "print(\"Vertices in layer t2:\", G.layer_vertex_set(aa_t2))\n",
    "\n",
    "print(\"Intra edges in t1:\", G.layer_edge_set(aa_t1))\n",
    "print(\"Intra edges in t2:\", G.layer_edge_set(aa_t2))\n",
    "\n",
    "print(\"Edges touching t1 (intra+inter+coupling):\",\n",
    "      G.layer_edge_set(aa_t1, include_inter=True, include_coupling=True))\n",
    "print(\"Edges touching t2 (intra+inter+coupling):\",\n",
    "      G.layer_edge_set(aa_t2, include_inter=True, include_coupling=True))\n",
    "\n",
    "# ---------- pure Kivela layer algebra (set-based) ----------\n",
    "\n",
    "print(\"\\n=== Kivela layer algebra (set view) ===\")\n",
    "res_union = G.layer_union([aa_t1, aa_t2])\n",
    "print(\"Union vertices (t1 ∪ t2):\", res_union[\"vertices\"])\n",
    "print(\"Union edges   (t1 ∪ t2):\", res_union[\"edges\"])\n",
    "\n",
    "res_inter = G.layer_intersection([aa_t1, aa_t2])\n",
    "print(\"Intersection vertices (t1 ∩ t2):\", res_inter[\"vertices\"])\n",
    "print(\"Intersection edges   (t1 ∩ t2):\", res_inter[\"edges\"])\n",
    "\n",
    "res_diff = G.layer_difference(aa_t1, aa_t2)\n",
    "print(\"Difference vertices (t1 \\\\ t2):\", res_diff[\"vertices\"])\n",
    "print(\"Difference edges   (t1 \\\\ t2):\", res_diff[\"edges\"])\n",
    "\n",
    "# ---------- Kivela → slice bridge ----------\n",
    "\n",
    "print(\"\\n=== Slice creation from Kivela layers ===\")\n",
    "\n",
    "# single-layer slices\n",
    "sid_t1 = G.create_slice_from_layer(\"L_t1\", aa_t1)\n",
    "sid_t2 = G.create_slice_from_layer(\"L_t2\", aa_t2)\n",
    "\n",
    "print(\"All slices (incl. default):\", G.list_slices(include_default=True))\n",
    "print(\"Slice L_t1 vertices:\", G.get_slice_vertices(sid_t1))\n",
    "print(\"Slice L_t1 edges   :\", G.get_slice_edges(sid_t1))\n",
    "print(\"Slice L_t2 vertices:\", G.get_slice_vertices(sid_t2))\n",
    "print(\"Slice L_t2 edges   :\", G.get_slice_edges(sid_t2))\n",
    "\n",
    "# union / intersection / difference slices\n",
    "sid_union = G.create_slice_from_layer_union(\"L_union_t1_t2\", [aa_t1, aa_t2])\n",
    "sid_inter = G.create_slice_from_layer_intersection(\"L_inter_t1_t2\", [aa_t1, aa_t2])\n",
    "sid_diff  = G.create_slice_from_layer_difference(\"L_diff_t1_t2\", aa_t1, aa_t2)\n",
    "\n",
    "print(\"Slice L_union_t1_t2 vertices:\", G.get_slice_vertices(sid_union))\n",
    "print(\"Slice L_union_t1_t2 edges   :\", G.get_slice_edges(sid_union))\n",
    "\n",
    "print(\"Slice L_inter_t1_t2 vertices:\", G.get_slice_vertices(sid_inter))\n",
    "print(\"Slice L_inter_t1_t2 edges   :\", G.get_slice_edges(sid_inter))\n",
    "\n",
    "print(\"Slice L_diff_t1_t2 vertices:\", G.get_slice_vertices(sid_diff))\n",
    "print(\"Slice L_diff_t1_t2 edges   :\", G.get_slice_edges(sid_diff))\n",
    "\n",
    "# ---------- Subgraphs from Kivela layers ----------\n",
    "\n",
    "print(\"\\n=== Subgraphs from Kivela layers ===\")\n",
    "\n",
    "Gs_t1 = G.subgraph_from_layer_tuple(aa_t1)\n",
    "Gs_t2 = G.subgraph_from_layer_tuple(aa_t2)\n",
    "Gs_union = G.subgraph_from_layer_union([aa_t1, aa_t2])\n",
    "Gs_diff = G.subgraph_from_layer_difference(aa_t1, aa_t2)\n",
    "\n",
    "print(\"Subgraph t1 vertices:\", set(Gs_t1.entity_types.keys()))\n",
    "print(\"Subgraph t1 edges   :\", set(Gs_t1.edge_definitions.keys()))\n",
    "\n",
    "print(\"Subgraph t2 vertices:\", set(Gs_t2.entity_types.keys()))\n",
    "print(\"Subgraph t2 edges   :\", set(Gs_t2.edge_definitions.keys()))\n",
    "\n",
    "print(\"Subgraph union(t1,t2) vertices:\", set(Gs_union.entity_types.keys()))\n",
    "print(\"Subgraph union(t1,t2) edges   :\", set(Gs_union.edge_definitions.keys()))\n",
    "\n",
    "print(\"Subgraph t1\\\\t2 vertices:\", set(Gs_diff.entity_types.keys()))\n",
    "print(\"Subgraph t1\\\\t2 edges   :\", set(Gs_diff.edge_definitions.keys()))\n",
    "\n",
    "# ---------- Optional: test LayerManager if exposed as G.layers ----------\n",
    "\n",
    "if hasattr(G, \"layers\"):\n",
    "    print(\"\\n=== LayerManager high-level API ===\")\n",
    "    print(\"All layer tuples:\", G.layers.layer_tuples())\n",
    "    print(\"vertex_set(t1):\", G.layers.vertex_set(aa_t1))\n",
    "    print(\"edge_set(t1):\", G.layers.edge_set(aa_t1))\n",
    "\n",
    "    lm_union = G.layers.union([aa_t1, aa_t2])\n",
    "    print(\"LayerManager union vertices:\", lm_union[\"vertices\"])\n",
    "    print(\"LayerManager union edges   :\", lm_union[\"edges\"])\n",
    "\n",
    "    lm_sid_t1 = G.layers.to_slice(aa_t1, slice_id=\"LM_t1\")\n",
    "    print(\"LM_t1 slice vertices:\", G.get_slice_vertices(lm_sid_t1))\n",
    "    print(\"LM_t1 slice edges   :\", G.get_slice_edges(lm_sid_t1))\n",
    "\n",
    "    Gs_lm = G.layers.subgraph(aa_t1)\n",
    "    print(\"LayerManager subgraph(t1) vertices:\", set(Gs_lm.entity_types.keys()))\n",
    "    print(\"LayerManager subgraph(t1) edges   :\", set(Gs_lm.edge_definitions.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a08a31-1527-4c94-b484-08a7a1b0c973",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### graphtool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efc8e9c-665c-44e3-aafa-929fa5af061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_tool.all as gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539e9516-cfec-4339-84f9-0f5659b02085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.insert(0, ROOT)\n",
    "\n",
    "from annnet.adapters import graphtool_adapter as gtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c62b24-a4a7-4ee6-bb43-eef6d4895c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtG, manifest = gtt.to_graphtool(G)\n",
    "\n",
    "# reconstruct an AnnNet graph:\n",
    "G2 = gtt.from_graphtool(gtG, manifest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58077137-2f3f-4cd9-849f-3763d4891949",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a6ffc0-2328-4321-bb33-bb8df1fd7234",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = gt.sfdp_layout(gtG)\n",
    "\n",
    "# Draw with vertex ids as labels\n",
    "gt.graph_draw(\n",
    "    gtG,\n",
    "    pos=pos,\n",
    "    vertex_text=gtG.vp[\"id\"],\n",
    "    vertex_font_size=10,\n",
    "    output_size=(300,300),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca3b246-4ed6-4cb6-b76c-57144d6a81e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a layer tuple\n",
    "aa = (\"t1\",)  # for single-aspect \"time\"\n",
    "\n",
    "# subgraph of that layer\n",
    "G_t1 = G.subgraph_from_layer_tuple(aa)\n",
    "\n",
    "# project and draw\n",
    "gtG_t1, man_t1 = gtt.to_graphtool(G_t1)\n",
    "pos_t1 = gt.sfdp_layout(gtG_t1)\n",
    "gt.graph_draw(\n",
    "    gtG_t1,\n",
    "    pos=pos_t1,\n",
    "    vertex_text=gtG_t1.vp[\"id\"],\n",
    "    vertex_font_size=10,\n",
    "    output_size=(600, 600),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b9902f-46aa-4bf0-bad8-c36d8f1d1fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c80debc-971f-478c-bc3b-61c5f6f5a72f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### gt lazy proxies adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e81fb8-1daa-4f01-bb3e-e271ebe354dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "from annnet.core.graph import AnnNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9970ff23-b720-4692-9fe6-13619819f4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = AnnNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89e2f44-a99d-4ad1-841d-ad3e68bc0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_vertex(\"A\", age = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecac69a0-d17a-4886-83ff-897b54b51e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_vertex(\"B\", age = 7.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5720abe5-adb5-4f41-80d5-387e9b009486",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.vertex_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a8fa35-64bd-4ebc-8a4a-f473f141c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_edge(\"A\", \"B\", n = 78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b37fff-7301-45ec-80e0-9bb818d5e9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_edge(\"A\", \"B\", n = 67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524ad728-205e-4a8b-8936-a1d8d57fe09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.edge_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb5e588-4aa0-45ea-9d1d-7faba71f0b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "from annnet.core.graph import AnnNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77814bd8-dd82-43e6-bf29-370694e1cc70",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def build_simple():\n",
    "    G = AnnNet()\n",
    "    G.add_vertex(\"a\")\n",
    "    G.add_vertex(\"b\")\n",
    "    G.add_edge(\"a\", \"b\", weight=5.0)\n",
    "    return G\n",
    "\n",
    "# Basic call\n",
    "G = build_simple()\n",
    "dist = G.gt.topology.shortest_distance(G, source=\"a\", target=\"b\", weights=\"weight\")\n",
    "print(\"distance:\", float(dist))   # expected 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc9ac76-7e6a-457f-8093-443cbb3df711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directed\n",
    "G = AnnNet(directed=True)\n",
    "G.add_vertex(\"a\")\n",
    "G.add_vertex(\"b\")\n",
    "G.add_edge(\"a\", \"b\", weight=2.0)\n",
    "\n",
    "d1 = G.gt.topology.shortest_distance(G, source=\"a\", target=\"b\", weights=\"weight\")\n",
    "print(\"directed distance:\", float(d1))  # expected 2.0\n",
    "\n",
    "try:\n",
    "    d2 = G.gt.topology.shortest_distance(G, source=\"b\", target=\"a\", weights=\"weight\")\n",
    "    print(\"reverse directed distance:\", d2)\n",
    "except Exception as e:\n",
    "    print(\"reverse failed:\", type(e).__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e3e45a-f023-4f1b-b2e0-66471e66cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = build_simple()\n",
    "\n",
    "# AnnNet-tool version: must be `gtG.ep['weight']`\n",
    "gtG = G.gt.backend()\n",
    "\n",
    "# direct-graph-tool call (no proxy)\n",
    "from graph_tool import topology\n",
    "d_ref = topology.shortest_distance(gtG,\n",
    "                                   source=gtG.vertex(0),\n",
    "                                   target=gtG.vertex(1),\n",
    "                                   weights=gtG.ep[\"weight\"])\n",
    "\n",
    "d_proxy = G.gt.topology.shortest_distance(G, source=\"a\", target=\"b\", weights=\"weight\")\n",
    "\n",
    "print(\"direct vs proxy:\", float(d_ref), float(d_proxy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ea6a57-b676-40aa-9e2b-609b2dd2c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = AnnNet()\n",
    "G.add_vertex(\"x\")\n",
    "G.add_vertex(\"y\")\n",
    "G.add_edge(\"x\", \"y\", weight=10.0)\n",
    "G.add_edge(\"x\", \"y\", weight=1.0)    # smallest weight should dominate shortest paths\n",
    "\n",
    "d = G.gt.topology.shortest_distance(G, source=\"x\", target=\"y\", weights=\"weight\")\n",
    "print(\"parallel edges distance:\", float(d))  # expected 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54b6752-1fcb-46ad-b971-f733be6c4f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = AnnNet()\n",
    "G.add_vertex(\"a\")\n",
    "G.add_vertex(\"b\")\n",
    "G.add_vertex(\"c\")\n",
    "G.add_edge(\"a\", \"b\")\n",
    "G.add_edge(\"b\", \"c\")\n",
    "\n",
    "comp = G.gt.topology.label_components(G)\n",
    "vp = comp[0]  # vertex property map\n",
    "\n",
    "print(\"component of a:\", int(vp[G.gt.backend().vertex(0)]))\n",
    "print(\"component of c:\", int(vp[G.gt.backend().vertex(2)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82216fba-c500-4286-8a3e-261f7a6e7803",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = AnnNet()\n",
    "G.add_vertex(\"a\")\n",
    "G.add_vertex(\"b\")\n",
    "G.add_vertex(\"c\")\n",
    "G.add_edge(\"a\", \"b\")\n",
    "G.add_edge(\"b\", \"c\")\n",
    "\n",
    "vc, ec = G.gt.centrality.betweenness(G)\n",
    "\n",
    "print(\"betweenness(a) =\", float(vc[G.gt.backend().vertex(0)]))\n",
    "print(\"betweenness(b) =\", float(vc[G.gt.backend().vertex(1)]))\n",
    "print(\"betweenness(c) =\", float(vc[G.gt.backend().vertex(2)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184acfe1-8d60-4cb9-9b6c-51449460943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmap = G.gt.topology.shortest_distance(G, source=\"a\", weights=\"weight\")\n",
    "print(\"distance map entry b:\", float(dmap[G.gt.backend().vertex(1)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8007320a-b256-47ba-b6cf-9b867ec00647",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = build_simple()\n",
    "\n",
    "try:\n",
    "    G.gt.topology.shortest_distance(G, source=\"zzz\", target=\"a\", weights=\"weight\")\n",
    "except Exception as e:\n",
    "    print(\"Caught error:\", type(e).__name__, str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23834c81-d5b2-4e76-861c-4ec1907194f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g= G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4262a1-45a2-47cd-a929-bd1e5ea4a831",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31145c17-96be-4bb9-b6fe-6c29467cfdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.vertex_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe84f018-f79e-465b-aa3d-f3c6df9eca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_vertex(\"v\", name = 67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f98e38f-ab47-40eb-be98-1b520b66bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.vertex_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6190df-c8c6-45c5-b39a-ff5b7500d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.set_vertex_attrs(\"v\", a = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6cab98-7e6f-4f55-86ce-4e997e18d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.vertex_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a87e2a-6e5a-497d-8851-a56842cac68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8eb308-8d66-43f2-bb24-68eb2e73ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.set_edge_attrs(\"edge_0\", age = 78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae49f7-fb5b-474a-9687-31cb0d9b96cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.edge_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a1b13-1564-4c24-b244-7daf777996a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.set_vertex_attrs(\"v\", name = 8888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e70246-6cad-4939-ba77-b92b02c8f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.vertex_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2573ee7e-475b-43a9-bdce-07e83073b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.set_vertex_attrs(\"tt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3b0ac4-ec89-49eb-b8d5-b7750d66eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.vertex_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b5099a-1245-4dfa-8ee3-5efb4fdc2035",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### CX2 adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5779200-2514-400b-abfa-3c2ceb3794ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "from annnet.core.graph import AnnNet\n",
    "from annnet.adapters import cx2_adapter as cx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a4a8f5-fcef-4f64-9508-8b76b1d33f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from annnet.io import io_annnet as ia\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110879c7-215e-449b-870c-d470ada1b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = ia.read(\"ppi.annnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c647e2-7719-4c24-9981-2f45d7a493d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.vertex_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9c2692-a54b-4a59-8402-8614b282d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk = cx.to_cx2(G)\n",
    "\n",
    "ex = cx.to_cx2(G, hyperedges= \"expand\")\n",
    "\n",
    "rf = cx.to_cx2(G, hyperedges= \"reify\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a59f17e-8501-485e-90a6-ed380c5257a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Assuming 'cx2_data' is the variable holding your list of dictionaries\n",
    "output_file = \"sk.cx2\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(sk, f)\n",
    "\n",
    "print(f\"Saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92f2331-b3a2-4113-bc6f-1ff6cfa0819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Assuming 'cx2_data' is the variable holding your list of dictionaries\n",
    "output_file = \"ex.cx2\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(ex, f)\n",
    "\n",
    "print(f\"Saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbebc09-409a-4317-bc77-82e25e2eed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Assuming 'cx2_data' is the variable holding your list of dictionaries\n",
    "output_file = \"rf.cx2\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(rf, f)\n",
    "\n",
    "print(f\"Saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d83bd1-07a9-4989-af7c-554a661d0802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple():\n",
    "    G = AnnNet()\n",
    "    G.add_vertex(\"a\")\n",
    "    G.add_vertex(\"b\")\n",
    "    G.add_edge(\"a\", \"b\", weight=5.0)\n",
    "    G.add_hyperedge(members=[\"A\",\"C\",\"D\"], weight=1.0, tag=\"complex\")\n",
    "    G.add_hyperedge(head=[\"A\",\"B\"], tail=[\"C\",\"D\"], weight=1.0, reaction=\"A+B->C+D\")\n",
    "    return G\n",
    "\n",
    "# Basic call\n",
    "Gs = build_simple()\n",
    "ts = cx.to_cx2(Gs, hyperedges= \"reify\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d16d1d-c92d-470d-9aab-6ce3295bda75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Assuming 'cx2_data' is the variable holding your list of dictionaries\n",
    "output_file = \"ts.cx2\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(ts, f)\n",
    "\n",
    "print(f\"Saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1071ff-81cd-4f51-87cf-9f2da9c1bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsg= cx.from_cx2('ts.cx2')\n",
    "\n",
    "tsg.edges_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cf873f-79d6-49ba-b6bd-675167839f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "skg= cx.from_cx2('sk.cx2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa2ef24-5d82-4dd5-9df1-b228dae83377",
   "metadata": {},
   "outputs": [],
   "source": [
    "exg = cx.from_cx2('ex.cx2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caf0bf0-523a-4ed8-a8cc-3f2ebcf36cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfg = cx.from_cx2(\"rf.cx2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c797b0e-6fa2-4b1b-b990-6eafe0ffadec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skg.vertex_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef905053-7ba1-49cd-a0ef-eabd472321d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## AnnNet explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbe39b4-4927-437d-aeed-12d040a6668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = AnnNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4137178f-a3e4-4865-acd4-9ac595ff62ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_edge(\"a\", \"b\",  edge_id= \"aa12\", as_entity=True, name = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92606a66-9af6-4205-807c-3e32d838eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_edge(\"a\", \"c\",  edge_id= \"a13\", as_entity=True, age = \"rezf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2327f050-7648-41a3-bf79-ffa4bd89e89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728799f0-c167-4da6-b467-59fb14c36d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_edge(\"aa12\", \"c\",  edge_id= 13, as_entity=True, a = 67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee29cd2-f90a-4294-8126-e499e6ca12ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77548258-6149-4b12-aff8-05636575adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_edge(\"aa12\", \"a13\", name = \"UIYG\", a = 6.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7725d5-568a-4083-9e90-16c45121c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6ba277-7524-48ff-b333-e9ac0a885c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.edge_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d136f-92b4-4eba-9b14-4de936fdd3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_hyperedge(members= [\"a\", \"b\", \"aa12\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697d9d47-9963-4663-b80d-a5ec166d3434",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.set_edge_attrs(\"edge_1\", name = \"233\", zefzf = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f62c1-4619-4547-a233-7c592d30cd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.edge_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c375d101-dac9-49d1-8ce6-a7b576118df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.edge_definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b68faa1-e26b-40d9-a097-950d28562eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.edges_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e26068-894a-4d0c-91c5-f38845ca65d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "g._matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a79c99-138a-49e2-844e-73fd95fb0b37",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b3276-2598-49af-b69d-657eed98b31e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# edge entites\n",
    "from annnet.core.graph import AnnNet\n",
    "from benchmarks.harness.metrics import measure\n",
    "import tracemalloc\n",
    "\n",
    "\n",
    "def _measure_mem(fn):\n",
    "    tracemalloc.start()\n",
    "    before = tracemalloc.take_snapshot()\n",
    "    fn()\n",
    "    after = tracemalloc.take_snapshot()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    stats = after.compare_to(before, \"filename\")\n",
    "    peak_bytes = sum(stat.size_diff for stat in stats)\n",
    "    return peak_bytes\n",
    "\n",
    "\n",
    "def run(scale):\n",
    "    results = {}\n",
    "    G = AnnNet(directed=True)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 0) Base graph construction (baseline cost)\n",
    "    # ------------------------------------------------------------\n",
    "    with measure() as m_vertices:\n",
    "        mem_vertices = _measure_mem(\n",
    "            lambda: G.add_vertices_bulk(\n",
    "                ({\"vertex_id\": f\"v{i}\"} for i in range(scale.vertices)),\n",
    "                slice=\"base\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    with measure() as m_edges:\n",
    "        mem_edges = _measure_mem(\n",
    "            lambda: G.add_edges_bulk(\n",
    "                {\n",
    "                    \"source\": f\"v{i % scale.vertices}\",\n",
    "                    \"target\": f\"v{(i + 1) % scale.vertices}\",\n",
    "                    \"weight\": 1.0,\n",
    "                }\n",
    "                for i in range(scale.edges)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    base_edges = list(G.edges())\n",
    "\n",
    "    results[\"base_vertices\"] = {\n",
    "        \"count\": scale.vertices,\n",
    "        \"wall_time_s\": m_vertices[\"wall_time_s\"],\n",
    "        \"bytes\": mem_vertices,\n",
    "        \"bytes_per_item\": mem_vertices / max(1, scale.vertices),\n",
    "    }\n",
    "\n",
    "    results[\"base_edges\"] = {\n",
    "        \"count\": scale.edges,\n",
    "        \"wall_time_s\": m_edges[\"wall_time_s\"],\n",
    "        \"bytes\": mem_edges,\n",
    "        \"bytes_per_item\": mem_edges / max(1, scale.edges),\n",
    "    }\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 1) Node -> Edge edge creation (no reification)\n",
    "    # ------------------------------------------------------------\n",
    "    node_edge_ids = []\n",
    "\n",
    "    def _node_edge_create():\n",
    "        for i, eid in enumerate(base_edges):\n",
    "            u = f\"v{i % scale.vertices}\"\n",
    "            node_edge_ids.append(\n",
    "                G.add_edge(u, eid, weight=1.0, as_entity=False)\n",
    "            )\n",
    "\n",
    "    with measure() as m_node_edge_create:\n",
    "        mem_node_edge_create = _measure_mem(_node_edge_create)\n",
    "\n",
    "    results[\"node_to_edge_create\"] = {\n",
    "        \"count\": len(node_edge_ids),\n",
    "        \"wall_time_s\": m_node_edge_create[\"wall_time_s\"],\n",
    "        \"bytes\": mem_node_edge_create,\n",
    "        \"bytes_per_item\": mem_node_edge_create / max(1, len(node_edge_ids)),\n",
    "    }\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 2) Edge reification (bulk)\n",
    "    # ------------------------------------------------------------\n",
    "    with measure() as m_reify:\n",
    "        mem_reify = _measure_mem(\n",
    "            lambda: G.add_edge_entities_bulk(node_edge_ids, slice=\"edge_entities\")\n",
    "        )\n",
    "\n",
    "    results[\"edge_reification_bulk\"] = {\n",
    "        \"count\": len(node_edge_ids),\n",
    "        \"wall_time_s\": m_reify[\"wall_time_s\"],\n",
    "        \"bytes\": mem_reify,\n",
    "        \"bytes_per_item\": mem_reify / max(1, len(node_edge_ids)),\n",
    "    }\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 3) Edge -> Edge creation + reification\n",
    "    # ------------------------------------------------------------\n",
    "    edge_entities = [\n",
    "        e for e in node_edge_ids\n",
    "        if e in G.entity_types and G.entity_types[e] == \"edge\"\n",
    "    ]\n",
    "\n",
    "    ee_ids = []\n",
    "\n",
    "    def _edge_edge_create():\n",
    "        for i in range(len(edge_entities) - 1):\n",
    "            ee_ids.append(\n",
    "                G.add_edge(\n",
    "                    edge_entities[i],\n",
    "                    edge_entities[i + 1],\n",
    "                    weight=1.0,\n",
    "                    as_entity=False,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    with measure() as m_edge_edge_create:\n",
    "        mem_edge_edge_create = _measure_mem(_edge_edge_create)\n",
    "\n",
    "    with measure() as m_edge_edge_reify:\n",
    "        mem_edge_edge_reify = _measure_mem(\n",
    "            lambda: G.add_edge_entities_bulk(ee_ids, slice=\"edge_edge_entities\")\n",
    "        )\n",
    "\n",
    "    results[\"edge_to_edge_create\"] = {\n",
    "        \"count\": len(ee_ids),\n",
    "        \"wall_time_s\": m_edge_edge_create[\"wall_time_s\"],\n",
    "        \"bytes\": mem_edge_edge_create,\n",
    "        \"bytes_per_item\": mem_edge_edge_create / max(1, len(ee_ids)),\n",
    "    }\n",
    "\n",
    "    results[\"edge_to_edge_reify\"] = {\n",
    "        \"count\": len(ee_ids),\n",
    "        \"wall_time_s\": m_edge_edge_reify[\"wall_time_s\"],\n",
    "        \"bytes\": mem_edge_edge_reify,\n",
    "        \"bytes_per_item\": mem_edge_edge_reify / max(1, len(ee_ids)),\n",
    "    }\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 4) Attribute mutation on edge-entities\n",
    "    # ------------------------------------------------------------\n",
    "    attr_items = [\n",
    "        (\n",
    "            eid,\n",
    "            {\n",
    "                \"weight\": float(i % 5),\n",
    "                \"label\": f\"type_{i % 3}\",\n",
    "            },\n",
    "        )\n",
    "        for i, eid in enumerate(ee_ids)\n",
    "    ]\n",
    "\n",
    "    with measure() as m_attr:\n",
    "        mem_attr = _measure_mem(\n",
    "            lambda: G.add_edge_entities_bulk(attr_items, slice=\"edge_edge_entities\")\n",
    "        )\n",
    "\n",
    "    results[\"edge_entity_attr_update\"] = {\n",
    "        \"count\": len(attr_items),\n",
    "        \"wall_time_s\": m_attr[\"wall_time_s\"],\n",
    "        \"bytes\": mem_attr,\n",
    "        \"bytes_per_item\": mem_attr / max(1, len(attr_items)),\n",
    "    }\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Final counters\n",
    "    # ------------------------------------------------------------\n",
    "    results[\"final_counts\"] = {\n",
    "        \"vertices\": G.number_of_vertices(),\n",
    "        \"edges_total\": G.number_of_edges(),\n",
    "        \"edge_entities\": sum(\n",
    "            1 for t in G.entity_types.values() if t == \"edge\"\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f6f4158-5757-4aaf-9caf-79f1e7b5476f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# benchmarks/core/expressiveness.py\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "from annnet.core.graph import AnnNet\n",
    "import random\n",
    "import tempfile\n",
    "from annnet.core.graph import AnnNet\n",
    "from benchmarks.harness.metrics import measure\n",
    "\n",
    "\n",
    "def run(scale):\n",
    "    G = AnnNet(directed=True)\n",
    "\n",
    "    with measure() as m_vertices:\n",
    "        G.add_vertices_bulk(\n",
    "            ({\"vertex_id\": f\"v{i}\"} for i in range(scale.vertices)),\n",
    "            slice=\"base\",\n",
    "        )\n",
    "\n",
    "    with measure() as m_edges:\n",
    "        G.add_edges_bulk(\n",
    "            {\n",
    "                \"source\": f\"v{i % scale.vertices}\",\n",
    "                \"target\": f\"v{(i * 37) % scale.vertices}\",\n",
    "                \"weight\": float(i % 7),\n",
    "                \"edge_type\": \"regular\",\n",
    "            }\n",
    "            for i in range(scale.edges))\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmp:\n",
    "        path = f\"{tmp}/graph.annnet\"\n",
    "\n",
    "        with measure() as m_write:\n",
    "            G.write(path, overwrite=True)\n",
    "\n",
    "        with measure() as m_read:\n",
    "            _ = AnnNet.read(path)\n",
    "    \n",
    "    return {\n",
    "        \"vertices\": m_vertices,\n",
    "        \"edges\": m_edges,\n",
    "        \"total_vertices\": G.number_of_vertices(),\n",
    "        \"total_edges\": G.number_of_edges(),\n",
    "        \"write_annnet\": m_write,\n",
    "        \"read_annnet\": m_read,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "681b6248-72a2-4194-afd1-c7b478928ab8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# benchmarks/core/operations.py\n",
    "import random\n",
    "from annnet.core.graph import AnnNet\n",
    "from benchmarks.harness.metrics import measure\n",
    "\n",
    "\n",
    "def run(scale):\n",
    "    G = AnnNet(directed=True)\n",
    "    \n",
    "    # Build base graph\n",
    "    vertices = [f\"v{i}\" for i in range(scale.vertices)]\n",
    "    G.add_vertices_bulk(\n",
    "        ({\"vertex_id\": vid} for vid in vertices),\n",
    "        slice=\"base\",\n",
    "    )\n",
    "    \n",
    "    edges = []\n",
    "    for i in range(scale.edges):\n",
    "        edges.append({\n",
    "            \"source\": f\"v{i % scale.vertices}\",\n",
    "            \"target\": f\"v{(i * 37) % scale.vertices}\",\n",
    "            \"weight\": float(i % 7),\n",
    "            \"edge_type\": \"regular\",\n",
    "        })\n",
    "    G.add_edges_bulk(edges)\n",
    "    \n",
    "    hyperedges = []\n",
    "    for _ in range(scale.hyperedges):\n",
    "        hyperedges.append({\n",
    "            \"members\": random.sample(vertices, min(5, len(vertices))),\n",
    "            \"weight\": 1.0,\n",
    "        })\n",
    "    G.add_hyperedges_bulk(hyperedges)\n",
    "    \n",
    "    # Add slices\n",
    "    for i in range(3):\n",
    "        slice_name = f\"slice_{i}\"\n",
    "        G.add_slice(slice_name)\n",
    "        sample_edges = random.sample(list(G.edges()), min(scale.edges // 4, G.number_of_edges()))\n",
    "        G.add_edges_to_slice_bulk(slice_name, sample_edges)\n",
    "    \n",
    "    # Benchmark operations\n",
    "    \n",
    "    with measure() as m_copy:\n",
    "        G_copy = G.copy()\n",
    "    \n",
    "    with measure() as m_copy_history:\n",
    "        G_copy_hist = G.copy(history=True)\n",
    "    \n",
    "    with measure() as m_subgraph_vertices:\n",
    "        sample_v = random.sample(vertices, scale.vertices // 2)\n",
    "        G_sub_v = G.subgraph(sample_v)\n",
    "    \n",
    "    with measure() as m_subgraph_edges:\n",
    "        sample_e = random.sample(list(G.edges()), scale.edges // 2)\n",
    "        G_sub_e = G.edge_subgraph(sample_e)\n",
    "    \n",
    "    with measure() as m_extract_subgraph:\n",
    "        G_extract = G.extract_subgraph(\n",
    "            vertices=sample_v,\n",
    "            edges=sample_e\n",
    "        )\n",
    "    \n",
    "    with measure() as m_reverse:\n",
    "        G_rev = G.reverse()\n",
    "    \n",
    "    with measure() as m_subgraph_from_slice:\n",
    "        G_slice = G.subgraph_from_slice(\"slice_0\", resolve_slice_weights=True)\n",
    "    \n",
    "    with measure() as m_hash:\n",
    "        h = hash(G)\n",
    "    \n",
    "    with measure() as m_memory_usage:\n",
    "        mem = G.memory_usage()\n",
    "    \n",
    "    with measure() as m_vertex_incidence_sparse:\n",
    "        M_sparse = G.vertex_incidence_matrix(values=True, sparse=True)\n",
    "    \n",
    "    with measure() as m_vertex_incidence_dense:\n",
    "        M_dense = G.vertex_incidence_matrix(values=True, sparse=False)\n",
    "    \n",
    "    with measure() as m_vertex_incidence_lists:\n",
    "        inc_lists = G.get_vertex_incidence_matrix_as_lists(values=False)\n",
    "    \n",
    "    return {\n",
    "        \"copy\": m_copy,\n",
    "        \"copy_with_history\": m_copy_history,\n",
    "        \"subgraph_vertices\": m_subgraph_vertices,\n",
    "        \"subgraph_edges\": m_subgraph_edges,\n",
    "        \"extract_subgraph\": m_extract_subgraph,\n",
    "        \"reverse\": m_reverse,\n",
    "        \"subgraph_from_slice\": m_subgraph_from_slice,\n",
    "        \"hash\": m_hash,\n",
    "        \"memory_usage\": m_memory_usage,\n",
    "        \"vertex_incidence_sparse\": m_vertex_incidence_sparse,\n",
    "        \"vertex_incidence_dense\": m_vertex_incidence_dense,\n",
    "        \"vertex_incidence_lists\": m_vertex_incidence_lists,\n",
    "        \"total_vertices\": G.number_of_vertices(),\n",
    "        \"total_edges\": G.number_of_edges(),\n",
    "        \"subgraph_v_vertices\": G_sub_v.number_of_vertices(),\n",
    "        \"subgraph_v_edges\": G_sub_v.number_of_edges(),\n",
    "        \"subgraph_e_vertices\": G_sub_e.number_of_vertices(),\n",
    "        \"subgraph_e_edges\": G_sub_e.number_of_edges(),\n",
    "        \"memory_bytes\": mem,\n",
    "        \"graph_hash\": h,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef458565-778d-4240-860a-0f82e8430cc5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l1boll/miniconda3/envs/myenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# adapters\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "from annnet.core.graph import AnnNet\n",
    "import tempfile\n",
    "from benchmarks.harness.metrics import measure\n",
    "from annnet.adapters.networkx_adapter import to_nx, from_nx\n",
    "from annnet.io.json_io import to_json, from_json\n",
    "from annnet.adapters.pyg_adapter import to_pyg\n",
    "from annnet.io.cx2_io import from_cx2, to_cx2\n",
    "from annnet.io.SIF_io import to_sif, from_sif\n",
    "from annnet.io.SBML_io import from_sbml\n",
    "from annnet.io.dataframe_io import from_dataframes, to_dataframes\n",
    "from annnet.io.GraphML_io import from_graphml, to_graphml, from_gexf, to_gexf\n",
    "from annnet.io.GraphDir_Parquet_io import to_parquet_graphdir, from_parquet_graphdir\n",
    "from annnet.adapters.graphtool_adapter import from_graphtool, to_graphtool\n",
    "from annnet.adapters.igraph_adapter import from_igraph, to_igraph\n",
    "from annnet.core.graph import AnnNet\n",
    "import json\n",
    "\n",
    "\n",
    "def run(scale):\n",
    "    out = {}\n",
    "    graph = AnnNet(directed=True)\n",
    "    \n",
    "    with measure() as m_vertices:\n",
    "        graph.add_vertices_bulk(\n",
    "            ({\"vertex_id\": f\"v{i}\"} for i in range(scale.vertices)),\n",
    "            slice=\"base\",\n",
    "        )\n",
    "    \n",
    "    with measure() as m_edges:\n",
    "        graph.add_edges_bulk(\n",
    "            {\n",
    "                \"source\": f\"v{i % scale.vertices}\",\n",
    "                \"target\": f\"v{(i * 37) % scale.vertices}\",\n",
    "                \"weight\": float(i % 7),\n",
    "                \"edge_type\": \"regular\",\n",
    "            }\n",
    "            for i in range(scale.edges)\n",
    "        )\n",
    "    \n",
    "    out[\"total_vertices\"] = graph.number_of_vertices()\n",
    "    out[\"total_edges\"] = graph.number_of_edges()    \n",
    "    out[\"vertices\"] = m_vertices\n",
    "    out[\"edges\"] = m_edges\n",
    "    \n",
    "    # NetworkX adapter\n",
    "    with measure() as m_nx_export:\n",
    "        nxG, manifest = to_nx(graph)\n",
    "    with measure() as m_nx_import:\n",
    "        G2 = from_nx(nxG, manifest)\n",
    "    out[\"nx_export\"] = m_nx_export\n",
    "    out[\"nx_import\"] = m_nx_import\n",
    "    out[\"nx_vertices\"] = G2.number_of_vertices()\n",
    "    out[\"nx_edges\"] = G2.number_of_edges()\n",
    "    \n",
    "    # JSON adapter\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        path = os.path.join(td, \"graph.json\")\n",
    "        with measure() as m_json_export:\n",
    "            to_json(graph, path)\n",
    "        size_bytes = os.path.getsize(path)\n",
    "        with measure() as m_json_import:\n",
    "            G3 = from_json(path)\n",
    "    out[\"json_export\"] = m_json_export\n",
    "    out[\"json_import\"] = m_json_import\n",
    "    out[\"json_size_bytes\"] = size_bytes\n",
    "    out[\"json_vertices\"] = G3.number_of_vertices()\n",
    "    out[\"json_edges\"] = G3.number_of_edges()\n",
    "    \n",
    "    # PyG (PyTorch Geometric) adapter\n",
    "    with measure() as m_pyg_export:\n",
    "        data = to_pyg(graph)\n",
    "    tensor_bytes = sum(\n",
    "        t.element_size() * t.nelement()\n",
    "        for t in data.to_dict().values()\n",
    "        if hasattr(t, \"nelement\")\n",
    "    )\n",
    "    out[\"pyg_export\"] = m_pyg_export\n",
    "    out[\"pyg_tensor_bytes\"] = tensor_bytes\n",
    "    \n",
    "    # CX2 adapter\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        sk = to_cx2(graph)\n",
    "        cx2_path = os.path.join(td, \"graph.cx2\")\n",
    "        with measure() as m_cx2_export:\n",
    "            with open(cx2_path, \"w\") as f:\n",
    "                json.dump(sk, f)\n",
    "        cx2_size = os.path.getsize(cx2_path)\n",
    "        with measure() as m_cx2_import:\n",
    "            G4 = from_cx2(cx2_path)\n",
    "    out[\"cx2_export\"] = m_cx2_export\n",
    "    out[\"cx2_import\"] = m_cx2_import\n",
    "    out[\"cx2_size_bytes\"] = cx2_size\n",
    "    out[\"cx2_vertices\"] = G4.number_of_vertices()\n",
    "    out[\"cx2_edges\"] = G4.number_of_edges()\n",
    "    \n",
    "    # SIF adapter\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        sif_path = os.path.join(td, \"graph.sif\")\n",
    "        with measure() as m_sif_export:\n",
    "            to_sif(graph, sif_path)\n",
    "        sif_size = os.path.getsize(sif_path)\n",
    "        with measure() as m_sif_import:\n",
    "            G5 = from_sif(sif_path)\n",
    "    out[\"sif_export\"] = m_sif_export\n",
    "    out[\"sif_import\"] = m_sif_import\n",
    "    out[\"sif_size_bytes\"] = sif_size\n",
    "    out[\"sif_vertices\"] = G5.number_of_vertices()\n",
    "    out[\"sif_edges\"] = G5.number_of_edges()\n",
    "    \n",
    "    # DataFrame adapter\n",
    "    with measure() as m_df_export:\n",
    "        dfs = to_dataframes(graph)\n",
    "    df_size = 0\n",
    "    for df in dfs.values():\n",
    "        if hasattr(df, 'memory_usage'):\n",
    "            df_size += df.memory_usage(deep=True).sum()\n",
    "        elif hasattr(df, 'estimated_size'):\n",
    "            df_size += df.estimated_size()\n",
    "    with measure() as m_df_import:\n",
    "        G6 = from_dataframes(\n",
    "            nodes=dfs.get('nodes'),\n",
    "            edges=dfs.get('edges'),\n",
    "            hyperedges=dfs.get('hyperedges'),\n",
    "            slices=dfs.get('slices'),\n",
    "            slice_weights=dfs.get('slice_weights')\n",
    "        )\n",
    "    out[\"df_export\"] = m_df_export\n",
    "    out[\"df_import\"] = m_df_import\n",
    "    out[\"df_memory_bytes\"] = df_size\n",
    "    out[\"df_vertices\"] = G6.number_of_vertices()\n",
    "    out[\"df_edges\"] = G6.number_of_edges()\n",
    "    \n",
    "    # GraphML adapter\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        graphml_path = os.path.join(td, \"graph.graphml\")\n",
    "        with measure() as m_graphml_export:\n",
    "            to_graphml(graph, graphml_path)\n",
    "        graphml_size = os.path.getsize(graphml_path)\n",
    "        with measure() as m_graphml_import:\n",
    "            G7 = from_graphml(graphml_path)\n",
    "    out[\"graphml_export\"] = m_graphml_export\n",
    "    out[\"graphml_import\"] = m_graphml_import\n",
    "    out[\"graphml_size_bytes\"] = graphml_size\n",
    "    out[\"graphml_vertices\"] = G7.number_of_vertices()\n",
    "    out[\"graphml_edges\"] = G7.number_of_edges()\n",
    "    \n",
    "    # GEXF adapter\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        gexf_path = os.path.join(td, \"graph.gexf\")\n",
    "        with measure() as m_gexf_export:\n",
    "            to_gexf(graph, gexf_path)\n",
    "        gexf_size = os.path.getsize(gexf_path)\n",
    "        with measure() as m_gexf_import:\n",
    "            G8 = from_gexf(gexf_path)\n",
    "    out[\"gexf_export\"] = m_gexf_export\n",
    "    out[\"gexf_import\"] = m_gexf_import\n",
    "    out[\"gexf_size_bytes\"] = gexf_size\n",
    "    out[\"gexf_vertices\"] = G8.number_of_vertices()\n",
    "    out[\"gexf_edges\"] = G8.number_of_edges()\n",
    "    \n",
    "    # Parquet GraphDir adapter\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        parquet_dir = os.path.join(td, \"graph_parquet\")\n",
    "        with measure() as m_parquet_export:\n",
    "            to_parquet_graphdir(graph, parquet_dir)\n",
    "        parquet_size = sum(\n",
    "            os.path.getsize(os.path.join(parquet_dir, f))\n",
    "            for f in os.listdir(parquet_dir)\n",
    "            if os.path.isfile(os.path.join(parquet_dir, f))\n",
    "        )\n",
    "        with measure() as m_parquet_import:\n",
    "            G9 = from_parquet_graphdir(parquet_dir)\n",
    "    out[\"parquet_export\"] = m_parquet_export\n",
    "    out[\"parquet_import\"] = m_parquet_import\n",
    "    out[\"parquet_size_bytes\"] = parquet_size\n",
    "    out[\"parquet_vertices\"] = G9.number_of_vertices()\n",
    "    out[\"parquet_edges\"] = G9.number_of_edges()\n",
    "    \n",
    "    # graph-tool adapter\n",
    "    try:\n",
    "        with measure() as m_gt_export:\n",
    "            gt_graph, gt_manifest = to_graphtool(graph)\n",
    "        with measure() as m_gt_import:\n",
    "            G10 = from_graphtool(gt_graph, gt_manifest)\n",
    "        out[\"graphtool_export\"] = m_gt_export\n",
    "        out[\"graphtool_import\"] = m_gt_import\n",
    "        out[\"graphtool_vertices\"] = G10.number_of_vertices()\n",
    "        out[\"graphtool_edges\"] = G10.number_of_edges()\n",
    "    except Exception as e:\n",
    "        out[\"graphtool_error\"] = str(e)\n",
    "    \n",
    "    # igraph adapter\n",
    "    try:\n",
    "        with measure() as m_ig_export:\n",
    "            ig_graph, ig_manifest = to_igraph(graph)\n",
    "        with measure() as m_ig_import:\n",
    "            G11 = from_igraph(ig_graph, ig_manifest)\n",
    "        out[\"igraph_export\"] = m_ig_export\n",
    "        out[\"igraph_import\"] = m_ig_import\n",
    "        out[\"igraph_vertices\"] = G11.number_of_vertices()\n",
    "        out[\"igraph_edges\"] = G11.number_of_edges()\n",
    "    except Exception as e:\n",
    "        out[\"igraph_error\"] = str(e)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90cf1718-c5fc-44dd-8153-0c0d88fe55cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l1boll/miniconda3/envs/myenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# each adapter\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "from annnet.core.graph import AnnNet\n",
    "import tempfile\n",
    "from benchmarks.harness.metrics import measure\n",
    "from annnet.adapters.networkx_adapter import to_nx, from_nx\n",
    "from annnet.io.json_io import to_json, from_json\n",
    "from annnet.adapters.pyg_adapter import to_pyg\n",
    "from annnet.io.cx2_io import from_cx2, to_cx2\n",
    "from annnet.io.SIF_io import to_sif, from_sif\n",
    "from annnet.io.SBML_io import from_sbml\n",
    "from annnet.io.dataframe_io import from_dataframes, to_dataframes\n",
    "from annnet.io.GraphML_io import from_graphml, to_graphml, from_gexf, to_gexf\n",
    "from annnet.io.GraphDir_Parquet_io import to_parquet_graphdir, from_parquet_graphdir\n",
    "from annnet.adapters.graphtool_adapter import from_graphtool, to_graphtool\n",
    "from annnet.adapters.igraph_adapter import from_igraph, to_igraph\n",
    "from annnet.core.graph import AnnNet\n",
    "import json\n",
    "import random\n",
    "\n",
    "\n",
    "def run(scale):\n",
    "    out = {}\n",
    "    graph = AnnNet(directed=True)\n",
    "    \n",
    "    with measure() as m_vertices:\n",
    "        graph.add_vertices_bulk(\n",
    "            ({\"vertex_id\": f\"v{i}\"} for i in range(scale.vertices)),\n",
    "            slice=\"base\",\n",
    "        )\n",
    "    \n",
    "    with measure() as m_edges:\n",
    "        graph.add_edges_bulk(\n",
    "            {\n",
    "                \"source\": f\"v{i % scale.vertices}\",\n",
    "                \"target\": f\"v{(i * 37) % scale.vertices}\",\n",
    "                \"weight\": float(i % 7),\n",
    "                \"edge_type\": \"regular\",\n",
    "            }\n",
    "            for i in range(scale.edges)\n",
    "        )\n",
    "    vertices = [f\"v{i}\" for i in range(scale.vertices)]\n",
    "    hyperedges = []\n",
    "    for _ in range(scale.hyperedges):\n",
    "        hyperedges.append({\n",
    "            \"members\": random.sample(vertices, min(5, len(vertices))),\n",
    "            \"weight\": 1.0,\n",
    "        })\n",
    "    \n",
    "    with measure() as m_he:\n",
    "        graph.add_hyperedges_bulk(hyperedges)\n",
    "\n",
    "    out[\"total_vertices\"] = graph.number_of_vertices()\n",
    "    out[\"total_edges\"] = graph.number_of_edges()\n",
    "    out[\"total_hyper_edges\"] = scale.hyperedges\n",
    "    out[\"vertices\"] = m_vertices\n",
    "    out[\"edges\"] = m_edges\n",
    "    out[\"hyperedges\"] = m_he\n",
    "    \n",
    "    # NetworkX adapter\n",
    "    with measure() as m_nx_export:\n",
    "        nxG, manifest = to_nx(graph, hyperedge_mode= \"expand\")\n",
    "    with measure() as m_nx_import:\n",
    "        G2 = from_nx(nxG, manifest)\n",
    "    out[\"nx_export\"] = m_nx_export\n",
    "    out[\"nx_import\"] = m_nx_import\n",
    "    out[\"nx_vertices\"] = G2.number_of_vertices()\n",
    "    out[\"nx_edges\"] = G2.number_of_edges()\n",
    "    \n",
    "    # JSON adapter\n",
    "    \"\"\"with tempfile.TemporaryDirectory() as td:\n",
    "        path = os.path.join(td, \"graph.json\")\n",
    "        with measure() as m_json_export:\n",
    "            to_json(graph, path)\n",
    "        size_bytes = os.path.getsize(path)\n",
    "        with measure() as m_json_import:\n",
    "            G3 = from_json(path)\n",
    "    out[\"json_export\"] = m_json_export\n",
    "    out[\"json_import\"] = m_json_import\n",
    "    out[\"json_size_bytes\"] = size_bytes\n",
    "    out[\"json_vertices\"] = G3.number_of_vertices()\n",
    "    out[\"json_edges\"] = G3.number_of_edges()\n",
    "    \"\"\"\n",
    "    # PyG (PyTorch Geometric) adapter\n",
    "    \"\"\"with measure() as m_pyg_export:\n",
    "        data = to_pyg(graph)\n",
    "    tensor_bytes = sum(\n",
    "        t.element_size() * t.nelement()\n",
    "        for t in data.to_dict().values()\n",
    "        if hasattr(t, \"nelement\")\n",
    "    )\n",
    "    out[\"pyg_export\"] = m_pyg_export\n",
    "    out[\"pyg_tensor_bytes\"] = tensor_bytes\n",
    "    \"\"\"\n",
    "    # CX2 adapter\n",
    "    \"\"\"with tempfile.TemporaryDirectory() as td:\n",
    "        sk = to_cx2(graph)\n",
    "        cx2_path = os.path.join(td, \"graph.cx2\")\n",
    "        with measure() as m_cx2_export:\n",
    "            with open(cx2_path, \"w\") as f:\n",
    "                json.dump(sk, f)\n",
    "        cx2_size = os.path.getsize(cx2_path)\n",
    "        with measure() as m_cx2_import:\n",
    "            G4 = from_cx2(cx2_path)\n",
    "    out[\"cx2_export\"] = m_cx2_export\n",
    "    out[\"cx2_import\"] = m_cx2_import\n",
    "    out[\"cx2_size_bytes\"] = cx2_size\n",
    "    out[\"cx2_vertices\"] = G4.number_of_vertices()\n",
    "    out[\"cx2_edges\"] = G4.number_of_edges()\n",
    "    \"\"\"\n",
    "    # SIF adapter\n",
    "    \"\"\"with tempfile.TemporaryDirectory() as td:\n",
    "        sif_path = os.path.join(td, \"graph.sif\")\n",
    "        with measure() as m_sif_export:\n",
    "            to_sif(graph, sif_path)\n",
    "        sif_size = os.path.getsize(sif_path)\n",
    "        with measure() as m_sif_import:\n",
    "            G5 = from_sif(sif_path)\n",
    "    out[\"sif_export\"] = m_sif_export\n",
    "    out[\"sif_import\"] = m_sif_import\n",
    "    out[\"sif_size_bytes\"] = sif_size\n",
    "    out[\"sif_vertices\"] = G5.number_of_vertices()\n",
    "    out[\"sif_edges\"] = G5.number_of_edges()\n",
    "    \"\"\"\n",
    "    # DataFrame adapter\n",
    "    \"\"\"with measure() as m_df_export:\n",
    "        dfs = to_dataframes(graph)\n",
    "    df_size = 0\n",
    "    for df in dfs.values():\n",
    "        if hasattr(df, 'memory_usage'):\n",
    "            df_size += df.memory_usage(deep=True).sum()\n",
    "        elif hasattr(df, 'estimated_size'):\n",
    "            df_size += df.estimated_size()\n",
    "    with measure() as m_df_import:\n",
    "        G6 = from_dataframes(\n",
    "            nodes=dfs.get('nodes'),\n",
    "            edges=dfs.get('edges'),\n",
    "            hyperedges=dfs.get('hyperedges'),\n",
    "            slices=dfs.get('slices'),\n",
    "            slice_weights=dfs.get('slice_weights')\n",
    "        )\n",
    "    out[\"df_export\"] = m_df_export\n",
    "    out[\"df_import\"] = m_df_import\n",
    "    out[\"df_memory_bytes\"] = df_size\n",
    "    out[\"df_vertices\"] = G6.number_of_vertices()\n",
    "    out[\"df_edges\"] = G6.number_of_edges()\n",
    "    \"\"\"\n",
    "    # GraphML adapter\n",
    "    \"\"\"with tempfile.TemporaryDirectory() as td:\n",
    "        graphml_path = os.path.join(td, \"graph.graphml\")\n",
    "        with measure() as m_graphml_export:\n",
    "            to_graphml(graph, graphml_path)\n",
    "        graphml_size = os.path.getsize(graphml_path)\n",
    "        with measure() as m_graphml_import:\n",
    "            G7 = from_graphml(graphml_path)\n",
    "    out[\"graphml_export\"] = m_graphml_export\n",
    "    out[\"graphml_import\"] = m_graphml_import\n",
    "    out[\"graphml_size_bytes\"] = graphml_size\n",
    "    out[\"graphml_vertices\"] = G7.number_of_vertices()\n",
    "    out[\"graphml_edges\"] = G7.number_of_edges()\n",
    "    \"\"\"\n",
    "    # GEXF adapter\n",
    "    \"\"\"with tempfile.TemporaryDirectory() as td:\n",
    "        gexf_path = os.path.join(td, \"graph.gexf\")\n",
    "        with measure() as m_gexf_export:\n",
    "            to_gexf(graph, gexf_path)\n",
    "        gexf_size = os.path.getsize(gexf_path)\n",
    "        with measure() as m_gexf_import:\n",
    "            G8 = from_gexf(gexf_path)\n",
    "    out[\"gexf_export\"] = m_gexf_export\n",
    "    out[\"gexf_import\"] = m_gexf_import\n",
    "    out[\"gexf_size_bytes\"] = gexf_size\n",
    "    out[\"gexf_vertices\"] = G8.number_of_vertices()\n",
    "    out[\"gexf_edges\"] = G8.number_of_edges()\n",
    "    \"\"\"\n",
    "    # Parquet GraphDir adapter\n",
    "    \"\"\"with tempfile.TemporaryDirectory() as td:\n",
    "        parquet_dir = os.path.join(td, \"graph_parquet\")\n",
    "        with measure() as m_parquet_export:\n",
    "            to_parquet_graphdir(graph, parquet_dir)\n",
    "        parquet_size = sum(\n",
    "            os.path.getsize(os.path.join(parquet_dir, f))\n",
    "            for f in os.listdir(parquet_dir)\n",
    "            if os.path.isfile(os.path.join(parquet_dir, f))\n",
    "        )\n",
    "        with measure() as m_parquet_import:\n",
    "            G9 = from_parquet_graphdir(parquet_dir)\n",
    "    out[\"parquet_export\"] = m_parquet_export\n",
    "    out[\"parquet_import\"] = m_parquet_import\n",
    "    out[\"parquet_size_bytes\"] = parquet_size\n",
    "    out[\"parquet_vertices\"] = G9.number_of_vertices()\n",
    "    out[\"parquet_edges\"] = G9.number_of_edges()\n",
    "    \"\"\"\n",
    "    # graph-tool adapter\n",
    "    \"\"\"try:\n",
    "        with measure() as m_gt_export:\n",
    "            gt_graph, gt_manifest = to_graphtool(graph)\n",
    "        with measure() as m_gt_import:\n",
    "            G10 = from_graphtool(gt_graph, gt_manifest)\n",
    "        out[\"graphtool_export\"] = m_gt_export\n",
    "        out[\"graphtool_import\"] = m_gt_import\n",
    "        out[\"graphtool_vertices\"] = G10.number_of_vertices()\n",
    "        out[\"graphtool_edges\"] = G10.number_of_edges()\n",
    "    except Exception as e:\n",
    "        out[\"graphtool_error\"] = str(e)\n",
    "    \"\"\"\n",
    "    # igraph adapter\n",
    "    \"\"\"try:\n",
    "        with measure() as m_ig_export:\n",
    "            ig_graph, ig_manifest = to_igraph(graph)\n",
    "        with measure() as m_ig_import:\n",
    "            G11 = from_igraph(ig_graph, ig_manifest)\n",
    "        out[\"igraph_export\"] = m_ig_export\n",
    "        out[\"igraph_import\"] = m_ig_import\n",
    "        out[\"igraph_vertices\"] = G11.number_of_vertices()\n",
    "        out[\"igraph_edges\"] = G11.number_of_edges()\n",
    "    except Exception as e:\n",
    "        out[\"igraph_error\"] = str(e)\n",
    "    \"\"\"\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1322d99-0de2-4edf-930d-ccc884bc763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class scale():\n",
    "    vertices = 10000\n",
    "    edges = 10000\n",
    "    slices = 3\n",
    "    hyperedges = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2b49faf-0cfd-4439-8dfd-65032a489961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_vertices': 10000,\n",
       " 'total_edges': 20000,\n",
       " 'total_hyper_edges': 10000,\n",
       " 'vertices': {'wall_time_s': 0.036541426001349464,\n",
       "  'rss_before_mb': 996.14453125,\n",
       "  'rss_after_mb': 1006.01953125,\n",
       "  'rss_delta_mb': 9.875},\n",
       " 'edges': {'wall_time_s': 0.1681860550015699,\n",
       "  'rss_before_mb': 1006.01953125,\n",
       "  'rss_after_mb': 1014.39453125,\n",
       "  'rss_delta_mb': 8.375},\n",
       " 'hyperedges': {'wall_time_s': 0.5542241750008543,\n",
       "  'rss_before_mb': 1015.39453125,\n",
       "  'rss_after_mb': 1041.01953125,\n",
       "  'rss_delta_mb': 25.625},\n",
       " 'nx_export': {'wall_time_s': 0.7821945069990761,\n",
       "  'rss_before_mb': 1041.01953125,\n",
       "  'rss_after_mb': 1139.89453125,\n",
       "  'rss_delta_mb': 98.875},\n",
       " 'nx_import': {'wall_time_s': 1.96360769599778,\n",
       "  'rss_before_mb': 1139.89453125,\n",
       "  'rss_after_mb': 1342.03515625,\n",
       "  'rss_delta_mb': 202.140625},\n",
       " 'nx_vertices': 10000,\n",
       " 'nx_edges': 20000}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41ffba65-7b31-44a1-b229-c4df1082814f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1740165 function calls in 1.125 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 83 to 30 due to restriction <30>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    0.000    0.000    1.124    0.562 /home/l1boll/miniconda3/envs/myenv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3665(run_code)\n",
      "        2    0.000    0.000    1.124    0.562 {built-in method builtins.exec}\n",
      "        1    0.011    0.011    1.124    1.124 /tmp/ipykernel_4446/3848574810.py:1(<module>)\n",
      "        1    0.410    0.410    1.113    1.113 /mnt/c/Users/pc/desktop/anananan/annnet/adapters/networkx_adapter.py:247(to_nx)\n",
      "   110000    0.349    0.000    0.396    0.000 /home/l1boll/miniconda3/envs/myenv/lib/python3.11/site-packages/networkx/classes/multidigraph.py:428(add_edge)\n",
      "        1    0.050    0.050    0.139    0.139 /mnt/c/Users/pc/desktop/anananan/annnet/adapters/networkx_adapter.py:73(_export_legacy)\n",
      "    20000    0.048    0.000    0.071    0.000 /mnt/c/Users/pc/desktop/anananan/annnet/adapters/_utils.py:47(_endpoint_coeff_map)\n",
      "    40000    0.050    0.000    0.066    0.000 /mnt/c/Users/pc/desktop/anananan/annnet/core/graph.py:1303(get_edge)\n",
      "   480002    0.045    0.000    0.045    0.000 {method 'get' of 'dict' objects}\n",
      "    60000    0.021    0.000    0.033    0.000 /mnt/c/Users/pc/desktop/anananan/annnet/adapters/_utils.py:5(_is_directed_eid)\n",
      "   130000    0.024    0.000    0.032    0.000 /home/l1boll/miniconda3/envs/myenv/lib/python3.11/site-packages/networkx/utils/misc.py:645(_clear_cache)\n",
      "   160001    0.030    0.000    0.030    0.000 {method 'update' of 'dict' objects}\n",
      "    20000    0.018    0.000    0.025    0.000 /home/l1boll/miniconda3/envs/myenv/lib/python3.11/site-packages/networkx/classes/digraph.py:450(add_node)\n",
      "        1    0.007    0.007    0.018    0.018 /mnt/c/Users/pc/desktop/anananan/annnet/adapters/networkx_adapter.py:621(<dictcomp>)\n",
      "   190017    0.012    0.000    0.012    0.000 {built-in method builtins.getattr}\n",
      "   180008    0.011    0.000    0.011    0.000 {built-in method builtins.isinstance}\n",
      "    20000    0.006    0.000    0.008    0.000 /mnt/c/Users/pc/desktop/anananan/annnet/adapters/_utils.py:18(_coerce_coeff_mapping)\n",
      "   130000    0.006    0.000    0.006    0.000 {method 'append' of 'list' objects}\n",
      "        7    0.000    0.000    0.006    0.001 /home/l1boll/miniconda3/envs/myenv/lib/python3.11/site-packages/polars/dataframe/frame.py:1852(to_dicts)\n",
      "        7    0.000    0.000    0.006    0.001 /home/l1boll/miniconda3/envs/myenv/lib/python3.11/site-packages/polars/dataframe/frame.py:11436(rows)\n",
      "        7    0.004    0.001    0.004    0.001 /home/l1boll/miniconda3/envs/myenv/lib/python3.11/site-packages/polars/dataframe/frame.py:11497(<listcomp>)\n",
      "        5    0.000    0.000    0.004    0.001 /mnt/c/Users/pc/desktop/anananan/annnet/adapters/networkx_adapter.py:283(_rows_from_table)\n",
      "        1    0.004    0.004    0.004    0.004 /mnt/c/Users/pc/desktop/anananan/annnet/adapters/networkx_adapter.py:404(<dictcomp>)\n",
      "        2    0.000    0.000    0.002    0.001 /mnt/c/Users/pc/desktop/anananan/annnet/adapters/networkx_adapter.py:103(_rows)\n",
      "    10000    0.002    0.000    0.002    0.000 /home/l1boll/miniconda3/envs/myenv/lib/python3.11/site-packages/networkx/classes/graph.py:473(__contains__)\n",
      "    39996    0.002    0.000    0.002    0.000 {built-in method builtins.len}\n",
      "    10000    0.002    0.000    0.002    0.000 /mnt/c/Users/pc/desktop/anananan/annnet/adapters/networkx_adapter.py:61(_attrs_to_dict)\n",
      "        7    0.002    0.000    0.002    0.000 {method 'row_tuples' of 'builtins.PyDataFrame' objects}\n",
      "     9996    0.002    0.000    0.002    0.000 {built-in method builtins.sorted}\n",
      "    30007    0.002    0.000    0.002    0.000 {method 'items' of 'dict' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x77f3d24ccf10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from annnet.adapters.networkx_adapter import to_nx\n",
    "\n",
    "graph = AnnNet()\n",
    "graph.add_vertices_bulk(\n",
    "    ({\"vertex_id\": f\"v{i}\"} for i in range(scale.vertices)),\n",
    "    slice=\"base\",\n",
    ")\n",
    "    \n",
    "graph.add_edges_bulk(\n",
    "    {\n",
    "        \"source\": f\"v{i % scale.vertices}\",\n",
    "        \"target\": f\"v{(i * 37) % scale.vertices}\",\n",
    "        \"weight\": float(i % 7),\n",
    "        \"edge_type\": \"regular\",\n",
    "    }\n",
    "    for i in range(scale.edges)\n",
    ")\n",
    "vertices = [f\"v{i}\" for i in range(scale.vertices)]\n",
    "hyperedges = []\n",
    "for _ in range(scale.hyperedges):\n",
    "    hyperedges.append({\n",
    "        \"members\": random.sample(vertices, min(5, len(vertices))),\n",
    "        \"weight\": 1.0,\n",
    "    })\n",
    "graph.add_hyperedges_bulk(hyperedges)\n",
    "\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "nxG, manifest = to_nx(graph, hyperedge_mode=\"reify\")\n",
    "pr.disable()\n",
    "\n",
    "stats = pstats.Stats(pr)\n",
    "stats.sort_stats('cumulative')\n",
    "stats.print_stats(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36c5653d-dfc9-4c26-9216-e0357d77bf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "g  = AnnNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "909c5bcc-c9e9-4591-8b48-145a2eccf142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.add_vertex(\"a\", a = 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35597136-8fef-46d5-bc29-873f4d45ae68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'edge_0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.add_edge(\"a\", \"b\", edge_id= \"edge_0\", a = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2501a9cc-6806-4576-acb2-3e9313fc09ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>vertex_id</th><th>a</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;a&quot;</td><td>6.0</td></tr><tr><td>&quot;b&quot;</td><td>8.9</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌───────────┬─────┐\n",
       "│ vertex_id ┆ a   │\n",
       "│ ---       ┆ --- │\n",
       "│ str       ┆ f64 │\n",
       "╞═══════════╪═════╡\n",
       "│ a         ┆ 6.0 │\n",
       "│ b         ┆ 8.9 │\n",
       "└───────────┴─────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.vertex_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f08239a-d4de-4d00-8eda-9d8669f004fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.set_vertex_attrs(\"b\", a = 8.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "879b6cff-1a3d-4415-acea-67337a74e8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>edge_id</th><th>a</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;edge_0&quot;</td><td>45.0</td></tr><tr><td>&quot;edge_1&quot;</td><td>4.5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌─────────┬──────┐\n",
       "│ edge_id ┆ a    │\n",
       "│ ---     ┆ ---  │\n",
       "│ str     ┆ f64  │\n",
       "╞═════════╪══════╡\n",
       "│ edge_0  ┆ 45.0 │\n",
       "│ edge_1  ┆ 4.5  │\n",
       "└─────────┴──────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edge_attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "375847d7-0fd7-4108-a6c0-480d23b68271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'edge_1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.add_edge(\"a\", \"c\", a = 4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9eac9d-9f84-4b6b-9069-459bca4977be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
