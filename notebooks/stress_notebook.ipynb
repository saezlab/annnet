{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1042de8d",
   "metadata": {},
   "source": [
    "# Graph — End‑to‑End Stress Notebook\n",
    "\n",
    "**Goal:** build a realistic, multi‑slice biological interaction graph with **tens of thousands** of vertices and a mix of **binary edges, hyperedges, and vertex–edge (edge‑entity) links**, then **exercise every public API**: slices, presence queries, propagation (`shared` / `all`), views, analytics, set operations, aggregations, subgraph/copy, deletions, auditing, and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0184fa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust import of Graph\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from time import perf_counter\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))  # must be the parent folder that CONTAINS 'annnet'\n",
    "\n",
    "from annnet.core.graph import Graph\n",
    "\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ab386c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters — choose a scale\n",
    "# - DEMO runs fast on laptops\n",
    "# - STRESS creates 10^4–10^5 scale objects; adjust upward to your machine limits\n",
    "\n",
    "SCALE = \"MID\"  # \"DEMO\" or \"STRESS\"\n",
    "\n",
    "if SCALE.upper() == \"DEMO\":\n",
    "    N_PROTEINS = 5_00\n",
    "    N_TRANSCRIPTS = 2_00\n",
    "    N_METABOLITES = 1_00\n",
    "    N_EDGE_ENTITIES = 40\n",
    "    N_BIN_EDGES = 25_00  # binary protein-protein interactions (base slice)\n",
    "    N_HYPER_COMPLEX = 1_00  # undirected complexes\n",
    "    N_HYPER_CASCADE = 1_00  # directed signaling cascades\n",
    "    N_vertex_EDGE_BIDIR = 2_00  # vertex<->edge-entity links (counted as pairs)\n",
    "elif SCALE.upper() == \"MID\":\n",
    "    N_PROTEINS = 10_000\n",
    "    N_TRANSCRIPTS = 5_000\n",
    "    N_METABOLITES = 20_000\n",
    "    N_EDGE_ENTITIES = 3_500\n",
    "    N_BIN_EDGES = 45_000\n",
    "    N_HYPER_COMPLEX = 4_000\n",
    "    N_HYPER_CASCADE = 3_000\n",
    "    N_vertex_EDGE_BIDIR = 5_000\n",
    "else:\n",
    "    N_PROTEINS = 200_000\n",
    "    N_TRANSCRIPTS = 50_000\n",
    "    N_METABOLITES = 20_000\n",
    "    N_EDGE_ENTITIES = 20_500\n",
    "    N_BIN_EDGES = 800_000\n",
    "    N_HYPER_COMPLEX = 20_000  # use commas? We'll correct below to int\n",
    "    N_HYPER_CASCADE = 20_000\n",
    "    N_vertex_EDGE_BIDIR = 15_000\n",
    "\n",
    "\n",
    "nn = N_PROTEINS + N_TRANSCRIPTS + N_METABOLITES\n",
    "ne = N_BIN_EDGES + N_EDGE_ENTITIES + N_HYPER_COMPLEX + N_HYPER_CASCADE + N_vertex_EDGE_BIDIR\n",
    "# fix typo for N_HYPER_COMPLEX in STRESS case\n",
    "if isinstance(N_HYPER_COMPLEX, tuple):\n",
    "    N_HYPER_COMPLEX = 20000\n",
    "\n",
    "sliceS = [\"Healthy\", \"Stressed\", \"Disease\", \"DrugA\", \"DrugB\"]\n",
    "ORDERED_FOR_TEMPORAL = [\"Healthy\", \"Stressed\", \"Disease\", \"DrugA\", \"DrugB\"]\n",
    "\n",
    "# How many parallel edges to create as duplicates between random pairs\n",
    "N_PARALLEL_DUPES = max(1, N_BIN_EDGES // 20)\n",
    "\n",
    "# Fraction of vertices seeded into each non-default slice (to make propagate='shared'/'all' meaningful)\n",
    "SEED_FRAC_PER_slice = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8886718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "\n",
    "\n",
    "def rand_weight(base=1.0, jitter=0.5):\n",
    "    # positive weight with variability\n",
    "    w = base + (random.random() - 0.5) * 2 * jitter\n",
    "    return max(0.01, w)\n",
    "\n",
    "\n",
    "def try_to_pandas(df):\n",
    "    if df is None:\n",
    "        return None\n",
    "    if \"polars\" in type(df).__module__.lower():\n",
    "        return df.to_pandas() if hasattr(df, \"to_pandas\") else None\n",
    "    return df  # assume already pandas-like\n",
    "\n",
    "\n",
    "def head_df(df, n=5):\n",
    "    p = try_to_pandas(df)\n",
    "    return p.head(n) if p is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a1f5394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slices ready: ['Healthy', 'Stressed', 'Disease', 'DrugA', 'DrugB'] active: Healthy\n"
     ]
    }
   ],
   "source": [
    "# Build graph & slices\n",
    "t0 = perf_counter()\n",
    "G = Graph(directed=True)\n",
    "\n",
    "for lid in sliceS:\n",
    "    G.add_slice(lid, desc=f\"condition={lid}\")\n",
    "G.set_active_slice(sliceS[0])\n",
    "build_slices_time = perf_counter() - t0\n",
    "print(\"slices ready:\", G.list_slices(), \"active:\", G.get_active_slice())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa680145-8739-462e-abae-6e01ccc7f981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.X().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1c91253-6eb4-4273-a1ee-a3991284af9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l1boll/miniconda3/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ---- progress helpers ----\n",
    "from time import perf_counter\n",
    "\n",
    "try:\n",
    "    from tqdm.auto import tqdm  # uses notebook bar if available\n",
    "\n",
    "    _TQDM = True\n",
    "except Exception:\n",
    "    _TQDM = False\n",
    "\n",
    "\n",
    "def prog_iter(it, total=None, desc=\"\", mininterval=0.25):\n",
    "    \"\"\"Wrap any iterable with a progress display (tqdm if available, else no-op).\"\"\"\n",
    "    if _TQDM:\n",
    "        return tqdm(it, total=total, desc=desc, mininterval=mininterval, leave=False)\n",
    "    return it\n",
    "\n",
    "\n",
    "def batched(iterable, batch_size):\n",
    "    \"\"\"Yield lists of size <= batch_size (Py<3.12 compatible).\"\"\"\n",
    "    buf = []\n",
    "    for x in iterable:\n",
    "        buf.append(x)\n",
    "        if len(buf) == batch_size:\n",
    "            yield buf\n",
    "            buf = []\n",
    "    if buf:\n",
    "        yield buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a46b7589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertices done. #vertices: 35000 Edge-entities: 3500 time(s)= 0.526\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "t = perf_counter()\n",
    "\n",
    "proteins = [f\"P{i}\" for i in range(1, N_PROTEINS + 1)]\n",
    "transcripts = [f\"T{i}\" for i in range(1, N_TRANSCRIPTS + 1)]\n",
    "metabolites = [f\"M{i}\" for i in range(1, N_METABOLITES + 1)]\n",
    "edge_entities = [f\"EE{i}\" for i in range(1, N_EDGE_ENTITIES + 1)]\n",
    "\n",
    "# --- Seed vertices in \"Healthy\" ---\n",
    "kinase_mask = rng.random(len(proteins)) < 0.15\n",
    "G.add_vertices_bulk(\n",
    "    (\n",
    "        {\"vertex_id\": p, \"kind\": \"protein\", **({\"family\": \"kinase\"} if km else {})}\n",
    "        for p, km in zip(proteins, kinase_mask)\n",
    "    ),\n",
    "    slice=\"Healthy\",\n",
    ")\n",
    "G.add_vertices_bulk(({\"vertex_id\": t, \"kind\": \"transcript\"} for t in transcripts), slice=\"Healthy\")\n",
    "G.add_vertices_bulk(({\"vertex_id\": m, \"kind\": \"metabolite\"} for m in metabolites), slice=\"Healthy\")\n",
    "\n",
    "# --- Edge-entities in \"Healthy\" (bulk) ---\n",
    "pathways = np.array([\"glycolysis\", \"tca\", \"mapk\", \"pi3k\"])\n",
    "drawn_pathways = pathways[rng.integers(0, len(pathways), size=len(edge_entities))]\n",
    "G.add_edge_entities_bulk(\n",
    "    (\n",
    "        {\"edge_entity_id\": ee, \"role\": \"enzyme\", \"pathway\": pw}\n",
    "        for ee, pw in zip(edge_entities, drawn_pathways)\n",
    "    ),\n",
    "    slice=\"Healthy\",\n",
    ")\n",
    "\n",
    "# --- Seed presence into other slices (bulk per slice) ---\n",
    "p_keep = SEED_FRAC_PER_slice\n",
    "for lid in sliceS[1:]:\n",
    "    pmask = rng.random(len(proteins)) < p_keep\n",
    "    tmask = rng.random(len(transcripts)) < p_keep\n",
    "    mmask = rng.random(len(metabolites)) < p_keep\n",
    "\n",
    "    G.add_vertices_bulk(\n",
    "        ({\"vertex_id\": p, \"kind\": \"protein\"} for p, keep in zip(proteins, pmask) if keep),\n",
    "        slice=lid,\n",
    "    )\n",
    "    G.add_vertices_bulk(\n",
    "        ({\"vertex_id\": t, \"kind\": \"transcript\"} for t, keep in zip(transcripts, tmask) if keep),\n",
    "        slice=lid,\n",
    "    )\n",
    "    G.add_vertices_bulk(\n",
    "        ({\"vertex_id\": m, \"kind\": \"metabolite\"} for m, keep in zip(metabolites, mmask) if keep),\n",
    "        slice=lid,\n",
    "    )\n",
    "\n",
    "build_vertices_time = perf_counter() - t\n",
    "print(\n",
    "    \"vertices done. #vertices:\",\n",
    "    G.number_of_vertices(),\n",
    "    \"Edge-entities:\",\n",
    "    sum(1 for k, v in G.entity_types.items() if v == \"edge\"),\n",
    "    \"time(s)=\",\n",
    "    round(build_vertices_time, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b171451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary edges built: 45000 total edges now: 47250 time(s)= 1.421\n"
     ]
    }
   ],
   "source": [
    "# Binary edges (PPIs mostly among proteins), defined in Healthy then sliceed variants\n",
    "from time import perf_counter\n",
    "\n",
    "t = perf_counter()\n",
    "\n",
    "# ---------- 1) Bulk create binary edges on \"Healthy\" ----------\n",
    "pairs = []\n",
    "need = N_BIN_EDGES\n",
    "names = proteins\n",
    "n = len(names)\n",
    "\n",
    "# Generate candidate pairs quickly; reject self-loops\n",
    "while len(pairs) < need:\n",
    "    k = min(need - len(pairs), max(1024, need // 4))\n",
    "    us = random.choices(names, k=k)\n",
    "    vs = random.choices(names, k=k)\n",
    "    for u, v in zip(us, vs):\n",
    "        if u != v:\n",
    "            pairs.append((u, v))\n",
    "        if len(pairs) == need:\n",
    "            break\n",
    "\n",
    "dirs = [random.random() < 0.8 for _ in range(need)]\n",
    "ws = [rand_weight(1.2, 0.6) for _ in range(need)]\n",
    "\n",
    "bulk = [\n",
    "    {\n",
    "        \"source\": u,\n",
    "        \"target\": v,\n",
    "        \"weight\": w,\n",
    "        \"edge_directed\": d,\n",
    "        \"edge_type\": \"regular\",\n",
    "        \"slice\": \"Healthy\",\n",
    "    }\n",
    "    for (u, v), w, d in zip(pairs, ws, dirs)\n",
    "]\n",
    "ppis = G.add_edges_bulk(bulk, slice=\"Healthy\")  # list of edge_ids\n",
    "\n",
    "# ---------- 2) Bulk add parallel dupes ----------\n",
    "if ppis and N_PARALLEL_DUPES > 0:\n",
    "    chosen = random.choices(ppis, k=N_PARALLEL_DUPES)\n",
    "    par_edges = []\n",
    "    for eid in chosen:\n",
    "        u, v, _ = G.edge_definitions[eid]\n",
    "        par_edges.append(\n",
    "            {\n",
    "                \"source\": u,\n",
    "                \"target\": v,\n",
    "                \"weight\": rand_weight(1.0, 0.3),\n",
    "                \"edge_type\": \"regular\",\n",
    "                \"slice\": \"Healthy\",\n",
    "            }\n",
    "        )\n",
    "    G.add_edges_bulk(par_edges, slice=\"Healthy\")\n",
    "\n",
    "# ---------- 3) Bulk per-slice variants ----------\n",
    "base_w = {eid: G.edge_weights[eid] for eid in ppis}\n",
    "\n",
    "for lid in sliceS[1:]:\n",
    "    # Add all PPI edges to this slice in one shot\n",
    "    G.add_edges_to_slice_bulk(lid, ppis)\n",
    "\n",
    "    # Compute modifiers and upsert all weights for this slice at once\n",
    "    weights_rows = []\n",
    "    for eid in ppis:\n",
    "        bw = base_w[eid]\n",
    "        factor = {\n",
    "            \"Stressed\": rand_weight(1.10, 0.10),\n",
    "            \"Disease\": (0.7 if random.random() < 0.4 else rand_weight(1.30, 0.15)),\n",
    "            \"DrugA\": rand_weight(0.9, 0.25),\n",
    "            \"DrugB\": rand_weight(1.2, 0.20),\n",
    "        }[lid]\n",
    "        weights_rows.append((eid, {\"weight\": bw * factor, \"note\": f\"slice={lid}\"}))\n",
    "\n",
    "    G.set_edge_slice_attrs_bulk(lid, weights_rows)\n",
    "\n",
    "build_binary_time = perf_counter() - t\n",
    "print(\n",
    "    \"Binary edges built:\",\n",
    "    len(ppis),\n",
    "    \"total edges now:\",\n",
    "    G.number_of_edges(),\n",
    "    \"time(s)=\",\n",
    "    round(build_binary_time, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fb9c145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Propagation examples added (shared/all).\n"
     ]
    }
   ],
   "source": [
    "# Propagation semantics via add_edge(..., propagate=...)\n",
    "t = perf_counter()\n",
    "# Ensure varied vertex presence across slices for a few pairs\n",
    "pairs = [(random.choice(proteins), random.choice(transcripts)) for _ in range(2000)]\n",
    "for u, v in pairs:\n",
    "    # 'shared': only slices where both endpoints already present\n",
    "    G.add_edge(\n",
    "        u, v, slice=\"Healthy\", edge_type=\"regular\", weight=rand_weight(0.8, 0.2), propagate=\"shared\"\n",
    "    )\n",
    "pairs2 = [(random.choice(proteins), random.choice(metabolites)) for _ in range(2000)]\n",
    "for u, v in pairs2:\n",
    "    # 'all': appears everywhere either endpoint exists (pulls other endpoint in)\n",
    "    G.add_edge(\n",
    "        u, v, slice=\"Healthy\", edge_type=\"regular\", weight=rand_weight(0.8, 0.2), propagate=\"all\"\n",
    "    )\n",
    "\n",
    "build_propagation_time = perf_counter() - t\n",
    "print(\"Propagation examples added (shared/all).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79d79ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperedges built: 4000 complexes ; 3000 cascades\n",
      "time(s)= 3.145\n"
     ]
    }
   ],
   "source": [
    "# Hyperedges: undirected complexes, directed cascades\n",
    "t = perf_counter()\n",
    "\n",
    "# ------------------ Complexes ------------------\n",
    "complex_payload = [\n",
    "    {\n",
    "        \"members\": random.sample(proteins, random.choice([3, 4, 5, 6])),\n",
    "        \"slice\": \"Healthy\",\n",
    "        \"weight\": rand_weight(1.0, 0.2),\n",
    "        \"attributes\": {\"tag\": \"complex\"},\n",
    "        # \"propagate\": \"all\",   # uncomment if you want auto-propagation\n",
    "    }\n",
    "    for _ in range(N_HYPER_COMPLEX)\n",
    "]\n",
    "\n",
    "complex_ids = G.add_hyperedges_bulk(complex_payload)\n",
    "\n",
    "\n",
    "# ------------------ Cascades ------------------\n",
    "cascade_payload = []\n",
    "tries = 0\n",
    "while len(cascade_payload) < N_HYPER_CASCADE and tries < N_HYPER_CASCADE * 5:\n",
    "    tries += 1\n",
    "    head = set(random.sample(proteins, random.choice([1, 2])))\n",
    "    tail = set(random.sample(proteins, random.choice([2, 3, 4])))\n",
    "    if head & tail:\n",
    "        continue\n",
    "\n",
    "    cascade_payload.append(\n",
    "        {\n",
    "            \"head\": list(head),\n",
    "            \"tail\": list(tail),\n",
    "            \"slice\": \"Healthy\",\n",
    "            \"weight\": rand_weight(1.0, 0.4),\n",
    "            \"attributes\": {\"tag\": \"cascade\"},\n",
    "            # \"propagate\": \"all\",   # if desired\n",
    "        }\n",
    "    )\n",
    "\n",
    "cascade_ids = G.add_hyperedges_bulk(cascade_payload)\n",
    "\n",
    "build_hyper_time = perf_counter() - t\n",
    "print(\"Hyperedges built:\", len(complex_ids), \"complexes ;\", len(cascade_ids), \"cascades\")\n",
    "print(\"time(s)=\",\n",
    "    round(build_hyper_time, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ece7e391-094e-4712-97f3-8d10205de236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building hybrid vertex–edge reactions...\n",
      "Hybrid vertex–edge reactions added: 5000\n",
      "Total time: 1.7379 seconds\n",
      "Average per reaction: 0.000348 seconds\n",
      "Graph entities: 38500\n",
      "Graph edges:    68250\n"
     ]
    }
   ],
   "source": [
    "print(\"Building hybrid vertex–edge reactions...\")\n",
    "\n",
    "t = perf_counter()\n",
    "\n",
    "for _ in range(N_vertex_EDGE_BIDIR):\n",
    "    ee = random.choice(edge_entities)\n",
    "    s  = random.choice(proteins + transcripts + metabolites)\n",
    "    tvertex = random.choice(proteins + transcripts + metabolites)\n",
    "\n",
    "    # Ensure entity exists in the slice (cheap if already added)\n",
    "    G.add_edge_entity(ee, slice=\"Healthy\")\n",
    "\n",
    "    # Vertex → Edge-Entity\n",
    "    eid1 = G.add_edge(\n",
    "        s, ee,\n",
    "        slice=\"Healthy\",\n",
    "        weight=rand_weight(1.0, 0.5)\n",
    "    )\n",
    "\n",
    "    # Edge-Entity → Vertex\n",
    "    eid2 = G.add_edge(\n",
    "        ee, tvertex,\n",
    "        slice=\"Healthy\",\n",
    "        weight=rand_weight(1.0, 0.5)\n",
    "    )\n",
    "\n",
    "    # Reflect edges to all other slices\n",
    "    for lid in sliceS[1:]:\n",
    "        G.add_edge_to_slice(lid, eid1)\n",
    "        G.add_edge_to_slice(lid, eid2)\n",
    "\n",
    "build_time = perf_counter() - t\n",
    "\n",
    "# ----------------------------\n",
    "# Results\n",
    "# ----------------------------\n",
    "print(f\"Hybrid vertex–edge reactions added: {N_vertex_EDGE_BIDIR}\")\n",
    "print(f\"Total time: {build_time:.4f} seconds\")\n",
    "print(f\"Average per reaction: {build_time / N_vertex_EDGE_BIDIR:.6f} seconds\")\n",
    "print(f\"Graph entities: {len(G.entity_to_idx)}\")\n",
    "print(f\"Graph edges:    {len(G.edge_to_idx)}\")\n",
    "\n",
    "build_vertexedge_time = perf_counter() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30b56ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertices: 35000 Edges: 68250\n",
      "Edge-entities: 3500\n"
     ]
    }
   ],
   "source": [
    "# Sanity & counts\n",
    "print(\"vertices:\", G.number_of_vertices(), \"Edges:\", G.number_of_edges())\n",
    "assert G.number_of_vertices() > 0 and G.number_of_edges() > 0\n",
    "\n",
    "# Edge-entity count\n",
    "edge_entity_count = sum(\n",
    "    1 for _id, et in G.entity_types.items() if et == \"edge\" and _id in set(edge_entities)\n",
    ")\n",
    "print(\"Edge-entities:\", edge_entity_count)\n",
    "assert edge_entity_count == len(edge_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "178d772a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Healthy] edges_view rows: 68250\n",
      "Top 5 binary edges in Healthy:\n",
      " shape: (5, 4)\n",
      "┌────────────┬────────┬────────┬──────────────────┐\n",
      "│ edge_id    ┆ source ┆ target ┆ effective_weight │\n",
      "│ ---        ┆ ---    ┆ ---    ┆ ---              │\n",
      "│ str        ┆ str    ┆ str    ┆ f64              │\n",
      "╞════════════╪════════╪════════╪══════════════════╡\n",
      "│ edge_13625 ┆ P2743  ┆ P2797  ┆ 1.799998         │\n",
      "│ edge_34485 ┆ P1362  ┆ P2343  ┆ 1.799948         │\n",
      "│ edge_29091 ┆ P9429  ┆ P393   ┆ 1.799938         │\n",
      "│ edge_18587 ┆ P5285  ┆ P9274  ┆ 1.799908         │\n",
      "│ edge_38697 ┆ P793   ┆ P5784  ┆ 1.7999           │\n",
      "└────────────┴────────┴────────┴──────────────────┘\n",
      "[Stressed] edges_view rows: 68250\n",
      "Top 5 binary edges in Stressed:\n",
      " shape: (5, 4)\n",
      "┌────────────┬────────┬────────┬──────────────────┐\n",
      "│ edge_id    ┆ source ┆ target ┆ effective_weight │\n",
      "│ ---        ┆ ---    ┆ ---    ┆ ---              │\n",
      "│ str        ┆ str    ┆ str    ┆ f64              │\n",
      "╞════════════╪════════╪════════╪══════════════════╡\n",
      "│ edge_15260 ┆ P449   ┆ P2071  ┆ 2.153693         │\n",
      "│ edge_40683 ┆ P8021  ┆ P5558  ┆ 2.150485         │\n",
      "│ edge_5152  ┆ P2578  ┆ P4935  ┆ 2.15002          │\n",
      "│ edge_14413 ┆ P6324  ┆ P7128  ┆ 2.149404         │\n",
      "│ edge_18954 ┆ P6657  ┆ P1516  ┆ 2.149123         │\n",
      "└────────────┴────────┴────────┴──────────────────┘\n",
      "[Disease] edges_view rows: 68250\n",
      "Top 5 binary edges in Disease:\n",
      " shape: (5, 4)\n",
      "┌────────────┬────────┬────────┬──────────────────┐\n",
      "│ edge_id    ┆ source ┆ target ┆ effective_weight │\n",
      "│ ---        ┆ ---    ┆ ---    ┆ ---              │\n",
      "│ str        ┆ str    ┆ str    ┆ f64              │\n",
      "╞════════════╪════════╪════════╪══════════════════╡\n",
      "│ edge_5005  ┆ P2692  ┆ P2909  ┆ 2.594391         │\n",
      "│ edge_36875 ┆ P806   ┆ P3707  ┆ 2.588356         │\n",
      "│ edge_36725 ┆ P8292  ┆ P724   ┆ 2.588308         │\n",
      "│ edge_13916 ┆ P1106  ┆ P7608  ┆ 2.587797         │\n",
      "│ edge_6509  ┆ P3045  ┆ P9244  ┆ 2.586556         │\n",
      "└────────────┴────────┴────────┴──────────────────┘\n",
      "[DrugA] edges_view rows: 68250\n",
      "Top 5 binary edges in DrugA:\n",
      " shape: (5, 4)\n",
      "┌────────────┬────────┬────────┬──────────────────┐\n",
      "│ edge_id    ┆ source ┆ target ┆ effective_weight │\n",
      "│ ---        ┆ ---    ┆ ---    ┆ ---              │\n",
      "│ str        ┆ str    ┆ str    ┆ f64              │\n",
      "╞════════════╪════════╪════════╪══════════════════╡\n",
      "│ edge_32795 ┆ P6135  ┆ P7930  ┆ 2.065288         │\n",
      "│ edge_36047 ┆ P1584  ┆ P826   ┆ 2.062219         │\n",
      "│ edge_9695  ┆ P4785  ┆ P8661  ┆ 2.06168          │\n",
      "│ edge_33276 ┆ P2935  ┆ P4426  ┆ 2.056046         │\n",
      "│ edge_18258 ┆ P773   ┆ P9359  ┆ 2.05198          │\n",
      "└────────────┴────────┴────────┴──────────────────┘\n",
      "[DrugB] edges_view rows: 68250\n",
      "Top 5 binary edges in DrugB:\n",
      " shape: (5, 4)\n",
      "┌────────────┬────────┬────────┬──────────────────┐\n",
      "│ edge_id    ┆ source ┆ target ┆ effective_weight │\n",
      "│ ---        ┆ ---    ┆ ---    ┆ ---              │\n",
      "│ str        ┆ str    ┆ str    ┆ f64              │\n",
      "╞════════════╪════════╪════════╪══════════════════╡\n",
      "│ edge_43418 ┆ P1738  ┆ P703   ┆ 2.515364         │\n",
      "│ edge_27975 ┆ P9274  ┆ P498   ┆ 2.514197         │\n",
      "│ edge_11229 ┆ P5096  ┆ P5179  ┆ 2.511762         │\n",
      "│ edge_30588 ┆ P8818  ┆ P8050  ┆ 2.510366         │\n",
      "│ edge_11139 ┆ P2056  ┆ P8250  ┆ 2.509893         │\n",
      "└────────────┴────────┴────────┴──────────────────┘\n",
      "vertices view cols: ['vertex_id', 'family', 'kind', 'role', 'pathway']\n",
      "slices view cols: ['slice_id', 'desc']\n"
     ]
    }
   ],
   "source": [
    "# Views & Top edges per slice\n",
    "try:\n",
    "    for lid in sliceS:\n",
    "        EV = G.edges_view(slice=lid, resolved_weight=True)\n",
    "        print(\n",
    "            f\"[{lid}] edges_view rows:\", getattr(EV, \"height\", getattr(EV, \"shape\", [\"?\", \"?\"])[0])\n",
    "        )\n",
    "        # filter binary only, sort by effective weight\n",
    "        if pl is not None and isinstance(EV, pl.DataFrame):\n",
    "            top = (\n",
    "                EV.filter(pl.col(\"kind\") == \"binary\")\n",
    "                .sort(\"effective_weight\", descending=True)\n",
    "                .select([\"edge_id\", \"source\", \"target\", \"effective_weight\"])\n",
    "                .head(5)\n",
    "            )\n",
    "            print(f\"Top 5 binary edges in {lid}:\\n\", top)\n",
    "        else:\n",
    "            # Try pandas-like\n",
    "            try:\n",
    "                df = EV\n",
    "                if hasattr(df, \"query\"):\n",
    "                    bf = (\n",
    "                        df.query(\"kind == 'binary'\")\n",
    "                        .sort_values(\"effective_weight\", ascending=False)\n",
    "                        .head(5)\n",
    "                    )\n",
    "                    print(bf[[\"edge_id\", \"source\", \"target\", \"effective_weight\"]])\n",
    "            except Exception:\n",
    "                pass\n",
    "except Exception as e:\n",
    "    print(\"edges_view failed softly:\", e)\n",
    "\n",
    "try:\n",
    "    NV = G.vertices_view()\n",
    "    LV = G.slices_view()\n",
    "    print(\"vertices view cols:\", getattr(NV, \"columns\", None))\n",
    "    print(\"slices view cols:\", getattr(LV, \"columns\", None))\n",
    "except Exception as e:\n",
    "    print(\"vertices_view/slices_view failed softly:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b57cd148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge presence across slices: ['Healthy', 'Stressed', 'Disease', 'DrugA', 'DrugB']\n",
      "vertex presence across slices: ['Healthy', 'Stressed', 'Disease', 'DrugA', 'DrugB']\n",
      "Hyperedge presence (members): {'Healthy': ['edge_54157']}\n",
      "Hyperedge presence (head/tail): {'Healthy': ['edge_58195']}\n"
     ]
    }
   ],
   "source": [
    "# Presence queries\n",
    "any_e = next(iter(G.edge_to_idx.keys()))\n",
    "print(\"Edge presence across slices:\", G.edge_presence_across_slices(edge_id=any_e))\n",
    "\n",
    "any_p = random.choice(proteins)\n",
    "print(\"vertex presence across slices:\", G.vertex_presence_across_slices(any_p))\n",
    "\n",
    "# Hyperedge presence by members and head/tail\n",
    "if complex_ids:\n",
    "    m = random.choice(complex_ids)\n",
    "    members = G.hyperedge_definitions[m].get(\"members\", set())\n",
    "    if members:\n",
    "        print(\n",
    "            \"Hyperedge presence (members):\",\n",
    "            G.hyperedge_presence_across_slices(members=set(members)),\n",
    "        )\n",
    "if cascade_ids:\n",
    "    h = random.choice(cascade_ids)\n",
    "    hd = G.hyperedge_definitions[h]\n",
    "    if hd.get(\"head\") and hd.get(\"tail\"):\n",
    "        print(\n",
    "            \"Hyperedge presence (head/tail):\",\n",
    "            G.hyperedge_presence_across_slices(head=set(hd[\"head\"]), tail=set(hd[\"tail\"])),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da23aa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors(P3276) sample: ['P752', 'P5437', 'P1827', 'P3068', 'P5122', 'P2827', 'P2141', 'P2561', 'P2942', 'P2273']\n",
      "Out(P3276) sample: ['P752', 'P5437', 'P1827', 'P3068', 'P5122', 'P2827', 'P2141', 'P2561', 'P2942', 'P2273']\n",
      "In(P3276) sample: ['P2141', 'P2942', 'P2273', 'P1132', 'P2534', 'P4824', 'P3068', 'P2509', 'P388']\n"
     ]
    }
   ],
   "source": [
    "# Traversal\n",
    "q = random.choice(proteins)\n",
    "print(f\"Neighbors({q}) sample:\", G.neighbors(q)[:10])\n",
    "print(f\"Out({q}) sample:\", G.out_neighbors(q)[:10])\n",
    "print(f\"In({q}) sample:\", G.in_neighbors(q)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "721928c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice stats keys: ['Healthy', 'Stressed', 'Disease', 'DrugA', 'DrugB']\n",
      "Conserved edges (present in all slices): 57625\n",
      "Disease-specific edges: 0\n",
      "Temporal edge changes entries: 4 vertex changes entries: 4\n"
     ]
    }
   ],
   "source": [
    "# slice analytics, conserved/specific, temporal\n",
    "stats = G.slice_statistics()\n",
    "print(\"slice stats keys:\", list(stats.keys())[:5])\n",
    "\n",
    "conserved = G.conserved_edges(min_slices=len(sliceS))\n",
    "print(\"Conserved edges (present in all slices):\", len(conserved))\n",
    "\n",
    "disease_specific = G.slice_specific_edges(\"Disease\")\n",
    "print(\"Disease-specific edges:\", len(disease_specific))\n",
    "\n",
    "changes_e = G.temporal_dynamics(ORDERED_FOR_TEMPORAL, metric=\"edge_change\")\n",
    "changes_n = G.temporal_dynamics(ORDERED_FOR_TEMPORAL, metric=\"vertex_change\")\n",
    "print(\"Temporal edge changes entries:\", len(changes_e), \"vertex changes entries:\", len(changes_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7953cd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Union edges>=intersection edges: True\n",
      "Derived slices exist: True True True\n",
      "Aggregated slices added.\n"
     ]
    }
   ],
   "source": [
    "# slice set ops and derived slices\n",
    "u = G.slice_union([\"Healthy\", \"Stressed\"])\n",
    "i = G.slice_intersection([\"Healthy\", \"Stressed\"])\n",
    "d = G.slice_difference(\"Healthy\", \"Stressed\")\n",
    "print(\"Union edges>=intersection edges:\", len(u[\"edges\"]) >= len(i[\"edges\"]))\n",
    "\n",
    "lid_u = G.create_slice_from_operation(\"HS_union\", u, desc=\"H∪S\")\n",
    "lid_i = G.create_slice_from_operation(\"HS_intersection\", i, desc=\"H∩S\")\n",
    "lid_d = G.create_slice_from_operation(\"H_minus_S\", d, desc=\"H\\\\S\")\n",
    "print(\n",
    "    \"Derived slices exist:\",\n",
    "    G.has_slice(\"HS_union\"),\n",
    "    G.has_slice(\"HS_intersection\"),\n",
    "    G.has_slice(\"H_minus_S\"),\n",
    ")\n",
    "\n",
    "# Aggregations\n",
    "G.create_aggregated_slice([\"Healthy\", \"Stressed\"], \"Agg_union\", method=\"union\", tag=\"agg_u\")\n",
    "G.create_aggregated_slice(\n",
    "    [\"Healthy\", \"Stressed\"], \"Agg_intersection\", method=\"intersection\", tag=\"agg_i\"\n",
    ")\n",
    "print(\"Aggregated slices added.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ac0baaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge list tuple length check (u,v,kind,id): True\n",
      "Global entity/edge counts: 38500 70886\n"
     ]
    }
   ],
   "source": [
    "# Edge list & global counts\n",
    "el = G.edge_list()\n",
    "print(\"Edge list tuple length check (u,v,kind,id):\", all(len(t) == 4 for t in el))\n",
    "print(\"Global entity/edge counts:\", G.global_entity_count(), G.global_edge_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41a4cf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DrugB subgraph vertices/edges: 33260 58532\n",
      "subgraph time 4.615317179999693\n"
     ]
    }
   ],
   "source": [
    "# Subgraph & copy\n",
    "t =  perf_counter()\n",
    "\n",
    "SG = G.subgraph_from_slice(\"DrugB\", resolve_slice_weights=True)\n",
    "print(\"DrugB subgraph vertices/edges:\", SG.number_of_vertices(), SG.number_of_edges())\n",
    "\n",
    "subgraph_time = perf_counter() - t\n",
    "print(f\"subgraph time {subgraph_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed38b0ce-5a35-4364-b730-9a249fcf9dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep copy OK.\n",
      "copy time 0.15654186499978096\n"
     ]
    }
   ],
   "source": [
    "t =  perf_counter()\n",
    "\n",
    "CP = G.copy(history= True)\n",
    "# quick consistency checks\n",
    "assert set(CP.vertices()) == set(G.vertices())\n",
    "assert set(CP.edges()) == set(G.edges())\n",
    "any_hyper = next(e for e, k in G.edge_kind.items() if k == \"hyper\")\n",
    "assert CP.edge_kind.get(any_hyper) == \"hyper\"\n",
    "for lid in G.list_slices(include_default=True):\n",
    "    assert CP._slices[lid][\"vertices\"] == G._slices[lid][\"vertices\"]\n",
    "    assert CP._slices[lid][\"edges\"] == G._slices[lid][\"edges\"]\n",
    "print(\"Deep copy OK.\")\n",
    "\n",
    "copy_time = perf_counter() - t\n",
    "print(f\"copy time {copy_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "038a3853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vert 1.912892913000178 s\n",
      "edge 1.0082518620001792 s\n",
      "After removals: vertices= 34900 edges= 66450\n"
     ]
    }
   ],
   "source": [
    "# Removals: drop a slice of vertices/edges\n",
    "\n",
    "t =  perf_counter()\n",
    "# Drop ~1% of proteins\n",
    "drop_vertices = random.sample(proteins, max(1, len(proteins) // 100))\n",
    "G.remove_vertices(drop_vertices)  # one pass\n",
    "remove_vertices_t = perf_counter() - t\n",
    "print(\"vert\", remove_vertices_t, \"s\")\n",
    "\n",
    "t =  perf_counter()\n",
    "# Drop up to 500 edges\n",
    "drop_edges = list(G.edge_to_idx.keys())[: min(500, len(G.edge_to_idx))]\n",
    "G.remove_edges(drop_edges)  # one pass\n",
    "remove_edges_t =  perf_counter() - t\n",
    "print(\"edge\", remove_edges_t, \"s\")\n",
    "\n",
    "\n",
    "print(\"After removals: vertices=\", G.number_of_vertices(), \"edges=\", G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdbf52ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audit keys: ['extra_vertex_rows', 'extra_edge_rows', 'missing_vertex_rows', 'missing_edge_rows', 'invalid_edge_slice_rows']\n",
      "Approx memory usage (bytes): 19844227\n"
     ]
    }
   ],
   "source": [
    "# Audit & memory\n",
    "audit = G.audit_attributes()\n",
    "mem_bytes = G.memory_usage()\n",
    "print(\"Audit keys:\", list(audit.keys())[:10])\n",
    "print(\"Approx memory usage (bytes):\", int(mem_bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d0a6f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_PROTEINS = 200_000\n",
      "N_TRANSCRIPTS = 50_000\n",
      "N_METABOLITES = 20_000\n",
      "N_EDGE_ENTITIES = 20_500\n",
      "N_BIN_EDGES = 800_000\n",
      "N_HYPER_COMPLEX = 20, 000\n",
      "N_HYPER_CASCADE = 20_000N_vertex_EDGE_BIDIR = 15_000\n",
      "Build timings (seconds)                 stage   seconds\n",
      "0  build_binary_edges  1.395666\n",
      "1    build_hyperedges  3.067335\n",
      "2        build_slices  0.007395\n",
      "3    build_vertexedge  1.757805\n",
      "4      build_vertices  0.512317\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBuild timings (seconds)\u001b[39m\u001b[33m\"\u001b[39m, df)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Simple chart\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     21\u001b[39m plt.figure()\n\u001b[32m     22\u001b[39m plt.bar(df[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m], df[\u001b[33m\"\u001b[39m\u001b[33mseconds\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Timing summary\n",
    "import pandas as pd\n",
    "\n",
    "timings = {\n",
    "    \"build_slices\": build_slices_time,\n",
    "    \"build_vertices\": build_vertices_time,\n",
    "    \"build_binary_edges\": build_binary_time,\n",
    "    \"build_hyperedges\": build_hyper_time,\n",
    "    \"build_vertexedge\": build_vertexedge_time,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(sorted(timings.items(), key=lambda x: x[0]), columns=[\"stage\", \"seconds\"])\n",
    "\n",
    "print(f\"N_PROTEINS = 200_000\\nN_TRANSCRIPTS = 50_000\\nN_METABOLITES = 20_000\\nN_EDGE_ENTITIES = 20_500\\nN_BIN_EDGES = 800_000\\nN_HYPER_COMPLEX = 20, 000\\nN_HYPER_CASCADE = 20_000N_vertex_EDGE_BIDIR = 15_000\")\n",
    "\n",
    "print(\"Build timings (seconds)\", df)\n",
    "\n",
    "# Simple chart\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(df[\"stage\"], df[\"seconds\"])\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"seconds\")\n",
    "plt.title(\"Graph Build Timings\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b9caf79-3ebf-4afb-8fe9-3dd76c2409c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: stress/demo.annnet\n",
      "write time:  1.736514597999303\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "out_dir = Path('stress'); out_dir.mkdir(exist_ok=True, parents=True)\n",
    "demo_path = out_dir/'demo.annnet'\n",
    "t = perf_counter()\n",
    "\n",
    "G.write(demo_path, overwrite=True)  # lossless save\n",
    "print('Wrote:', demo_path)\n",
    "\n",
    "writet = perf_counter() - t\n",
    "print (\"write time: \", writet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "950ea4e2-60f7-4a72-aa59-e315767be7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read time:  1.0972290130002875\n",
      "Round-trip OK? True\n"
     ]
    }
   ],
   "source": [
    "import annnet\n",
    "# Round-trip check\n",
    "t = perf_counter()\n",
    "G2 = annnet.Graph.read(demo_path)\n",
    "readt = perf_counter() - t\n",
    "print (\"read time: \", readt)\n",
    "\n",
    "\n",
    "print('Round-trip OK?', (G2.num_vertices, G2.num_edges) == (G.num_vertices, G.num_edges))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0b9441-31e9-4036-91ff-466934435c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (current_env)",
   "language": "python",
   "name": "current_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
