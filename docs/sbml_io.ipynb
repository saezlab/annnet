{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c12b598-c9e1-41a3-abb0-737ddce14b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "from annnet.adapters.SBML_adapter import BOUNDARY_SINK, BOUNDARY_SOURCE, from_sbml\n",
    "from annnet.core.graph import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "654f7605-7374-47c3-8886-fcd3de1aee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-libsbml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9583333-0495-46bf-9370-0dbe7d6a8716",
   "metadata": {},
   "source": [
    "# SBML adapter (Elowitz repressilator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0e890d3-c708-4e5c-826b-5e739987e56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertices: 8\n",
      "edges: 12\n",
      "boundary vertices: True True\n",
      "sample edges: ['Reaction1', 'Reaction2', 'Reaction3', 'Reaction4', 'Reaction5']\n"
     ]
    }
   ],
   "source": [
    "G = from_sbml(\"Elowitz.sbml.xml\", graph=Graph(directed=True), preserve_stoichiometry=True)\n",
    "\n",
    "print(\"vertices:\", G.num_vertices)  # expect 8 (6 real + 2 boundary)\n",
    "print(\"edges:\", G.num_edges)  # expect 12\n",
    "print(\"boundary vertices:\", BOUNDARY_SOURCE in G.entity_to_idx, BOUNDARY_SINK in G.entity_to_idx)\n",
    "print(\"sample edges:\", list(G.edge_to_idx)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11048c69-82f3-4b0e-91cd-bf88becb1eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Reaction1]\n",
      "  head (products): ['__BOUNDARY_SINK__']\n",
      "  tail (reactants): ['X']\n",
      "[Reaction4]\n",
      "  head (products): ['PX']\n",
      "  tail (reactants): ['__BOUNDARY_SOURCE__']\n"
     ]
    }
   ],
   "source": [
    "def show_reaction(eid: str):\n",
    "    if eid not in G.edge_to_idx:\n",
    "        print(\"no such edge:\", eid)\n",
    "        return\n",
    "    h = G.hyperedge_definitions[eid]\n",
    "    attrs = G.get_edge_attrs(eid)\n",
    "    sto = attrs.get(\n",
    "        \"stoich\"\n",
    "    )  # present if you didn't add set_hyperedge_coeffs OR adapter stored it anyway\n",
    "    print(f\"[{eid}]\")\n",
    "    print(\"  head (products):\", sorted(h[\"head\"]))\n",
    "    print(\"  tail (reactants):\", sorted(h[\"tail\"]))\n",
    "    if sto:\n",
    "        # filter zeros if any\n",
    "        sto = {k: float(v) for k, v in sto.items() if abs(float(v)) > 1e-12}\n",
    "        print(\"  stoich map:\", sto)\n",
    "\n",
    "\n",
    "# examples\n",
    "show_reaction(\"Reaction1\")\n",
    "show_reaction(\"Reaction4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58f2a65b-34b9-4f71-ac35-341ddccb2320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PX  produced_in=1  consumed_in=1\n",
      "  PY  produced_in=1  consumed_in=1\n",
      "  PZ  produced_in=1  consumed_in=1\n",
      "   X  produced_in=1  consumed_in=1\n",
      "   Y  produced_in=1  consumed_in=1\n",
      "   Z  produced_in=1  consumed_in=1\n"
     ]
    }
   ],
   "source": [
    "BOUNDARY = {BOUNDARY_SOURCE, BOUNDARY_SINK}\n",
    "\n",
    "produced = dict.fromkeys(G.entity_to_idx, 0)\n",
    "consumed = dict.fromkeys(G.entity_to_idx, 0)\n",
    "\n",
    "for eid in G.edge_to_idx:\n",
    "    h = G.hyperedge_definitions[eid]\n",
    "    for v in h[\"head\"]:\n",
    "        produced[v] += 1\n",
    "    for v in h[\"tail\"]:\n",
    "        consumed[v] += 1\n",
    "\n",
    "real_species = [v for v in G.entity_to_idx if v not in BOUNDARY]\n",
    "stats = [(v, produced[v], consumed[v]) for v in real_species]\n",
    "stats.sort(key=lambda t: (t[1], t[2]), reverse=True)\n",
    "for v, p, c in stats:\n",
    "    print(f\"{v:>4}  produced_in={p}  consumed_in={c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fc74446-5135-4491-87fa-fb892b2d97e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PX\n",
      "  as product : ['Reaction4']\n",
      "  as reactant: ['Reaction7']\n",
      "\n",
      "PY\n",
      "  as product : ['Reaction5']\n",
      "  as reactant: ['Reaction8']\n",
      "\n",
      "PZ\n",
      "  as product : ['Reaction6']\n",
      "  as reactant: ['Reaction9']\n",
      "\n",
      "X\n",
      "  as product : ['Reaction10']\n",
      "  as reactant: ['Reaction1']\n",
      "\n",
      "Y\n",
      "  as product : ['Reaction11']\n",
      "  as reactant: ['Reaction2']\n",
      "\n",
      "Z\n",
      "  as product : ['Reaction12']\n",
      "  as reactant: ['Reaction3']\n"
     ]
    }
   ],
   "source": [
    "species_to_reactions = {v: {\"as_product\": [], \"as_reactant\": []} for v in G.entity_to_idx}\n",
    "\n",
    "for eid in G.edge_to_idx:\n",
    "    h = G.hyperedge_definitions[eid]\n",
    "    for v in h[\"head\"]:\n",
    "        species_to_reactions[v][\"as_product\"].append(eid)\n",
    "    for v in h[\"tail\"]:\n",
    "        species_to_reactions[v][\"as_reactant\"].append(eid)\n",
    "\n",
    "# example: show for each real species\n",
    "for v in real_species:\n",
    "    rp = species_to_reactions[v][\"as_product\"]\n",
    "    rr = species_to_reactions[v][\"as_reactant\"]\n",
    "    print(f\"\\n{v}\")\n",
    "    print(\"  as product :\", rp)\n",
    "    print(\"  as reactant:\", rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29a1d7f7-32f0-4165-b44b-3dca2178ab9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signs consistent (based on available attrs): True\n",
      "columns balanced (based on available attrs): True\n"
     ]
    }
   ],
   "source": [
    "# signs: by definition head=products (+), tail=reactants (−)\n",
    "def signs_consistent(eid):\n",
    "    h = G.hyperedge_definitions[eid]\n",
    "    attrs = G.get_edge_attrs(eid)\n",
    "    sto = attrs.get(\"stoich\")\n",
    "    if not sto:\n",
    "        # no per-vertex coeffs exposed via attrs; just check sets are present\n",
    "        return bool(h[\"head\"] or h[\"tail\"])\n",
    "    # if stoich map exists, check sign consistency vs head/tail sets\n",
    "    ok = True\n",
    "    for v, coeff in sto.items():\n",
    "        coeff = float(coeff)\n",
    "        if v in h[\"head\"]:\n",
    "            ok &= coeff > 0\n",
    "        if v in h[\"tail\"]:\n",
    "            ok &= coeff < 0\n",
    "    return ok\n",
    "\n",
    "\n",
    "sign_ok_all = all(signs_consistent(e) for e in G.edge_to_idx)\n",
    "print(\"signs consistent (based on available attrs):\", sign_ok_all)\n",
    "\n",
    "\n",
    "# balance: if stoich map exists, sum should be ~0 including boundary vertices\n",
    "def balanced(eid):\n",
    "    attrs = G.get_edge_attrs(eid)\n",
    "    sto = attrs.get(\"stoich\")\n",
    "    if not sto:\n",
    "        return True  # can't check without exposed coeffs; treat as pass\n",
    "    s = sum(float(v) for v in sto.values())\n",
    "    return abs(s) < 1e-9\n",
    "\n",
    "\n",
    "bal_ok_all = all(balanced(e) for e in G.edge_to_idx)\n",
    "print(\"columns balanced (based on available attrs):\", bal_ok_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2946759-f0dd-4245-99e3-53402a51af2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nx vertices: 8  nx edges: 12\n",
      "top-degree vertices: [('__BOUNDARY_SOURCE__', 6), ('__BOUNDARY_SINK__', 6), ('PX', 2), ('PY', 2), ('PZ', 2), ('X', 2), ('Y', 2), ('Z', 2)]\n",
      "shortest_path failed: No path between X and PX.\n",
      "cycles(count): 0\n",
      "sample cycles: []\n",
      "neighbors(X): ['__BOUNDARY_SOURCE__']\n",
      "weakly components: 1\n",
      "largest component size: 8\n",
      "top degree_centrality: [(6, 0.8571428571428571), (7, 0.8571428571428571), (0, 0.2857142857142857), (1, 0.2857142857142857), (2, 0.2857142857142857)]\n",
      "subgraph failed: networkx has no callable 'vertices'\n"
     ]
    }
   ],
   "source": [
    "# degrees on your underlying NX projection (pass G explicitly)\n",
    "deg = dict(G.nx.degree(G=G))\n",
    "print(\"nx vertices:\", G.nx.number_of_nodes(G=G), \" nx edges:\", G.nx.number_of_edges(G=G))\n",
    "print(\"top-degree vertices:\", sorted(deg.items(), key=lambda kv: kv[1], reverse=True)[:10])\n",
    "\n",
    "# simple paths (between two species if connected in your projection)\n",
    "try:\n",
    "    path = G.nx.shortest_path(G=G, source=\"X\", target=\"PX\")  # tweak names if different\n",
    "    print(\"shortest path X→PX:\", path)\n",
    "except Exception as e:\n",
    "    print(\"shortest_path failed:\", e)\n",
    "\n",
    "# cycles (directed projection)\n",
    "try:\n",
    "    cyc = list(G.nx.simple_cycles(G=G))\n",
    "    print(\"cycles(count):\", len(cyc))\n",
    "    print(\"sample cycles:\", cyc[:3])\n",
    "except Exception as e:\n",
    "    print(\"simple_cycles failed:\", e)\n",
    "\n",
    "# neighbors / predecessors / successors\n",
    "try:\n",
    "    print(\"neighbors(X):\", list(G.nx.neighbors(G=G, n=\"X\")))\n",
    "except Exception as e:\n",
    "    print(\"neighbors failed:\", e)\n",
    "\n",
    "try:\n",
    "    print(\"successors(X):\", list(G.nx.successors(G=G, n=\"X\")))\n",
    "    print(\"predecessors(X):\", list(G.nx.predecessors(G=G, n=\"X\")))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# connected components (weakly for directed; else undirected)\n",
    "try:\n",
    "    comps = list(G.nx.weakly_connected_components(G=G))\n",
    "    print(\"weakly components:\", len(comps))\n",
    "    print(\"largest component size:\", max(len(c) for c in comps))\n",
    "except Exception:\n",
    "    try:\n",
    "        comps = list(G.nx.connected_components(G=G))\n",
    "        print(\"connected components:\", len(comps))\n",
    "        print(\"largest component size:\", max(len(c) for c in comps))\n",
    "    except Exception as e:\n",
    "        print(\"components failed:\", e)\n",
    "\n",
    "# degree centrality (works the same way)\n",
    "try:\n",
    "    dc = G.nx.degree_centrality(G=G)\n",
    "    print(\"top degree_centrality:\", sorted(dc.items(), key=lambda kv: kv[1], reverse=True)[:5])\n",
    "except Exception as e:\n",
    "    print(\"degree_centrality failed:\", e)\n",
    "\n",
    "# species-only subgraph with the proxy (filters out boundary vertices)\n",
    "BOUNDARY = {\"__BOUNDARY_SOURCE__\", \"__BOUNDARY_SINK__\"}\n",
    "try:\n",
    "    species = [n for n in G.nx.vertices(G=G) if n not in BOUNDARY]\n",
    "    SG = G.nx.subgraph(G=G, nbunch=species)  # returns an NX graph\n",
    "    print(\"species-subgraph vertices:\", SG.number_of_nodes(), \"edges:\", SG.number_of_edges())\n",
    "except Exception as e:\n",
    "    print(\"subgraph failed:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3bde9e-4fab-4923-8567-f4ebe5db22c5",
   "metadata": {},
   "source": [
    "# AnnNet API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa04d33d-41e0-499e-b644-49434f8b4b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CREATING MULTI-slice TEMPORAL GRAPH\n",
      "============================================================\n",
      "\n",
      "✓ Created 4 slices\n",
      "  slices: ['2022', '2023', '2024']\n"
     ]
    }
   ],
   "source": [
    "# Create graph\n",
    "G = Graph(directed=True)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CREATING MULTI-slice TEMPORAL GRAPH\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Add slices\n",
    "G.slices.add(\"2022\", year=2022, description=\"Year 2022\")\n",
    "G.slices.add(\"2023\", year=2023, description=\"Year 2023\")\n",
    "G.slices.add(\"2024\", year=2024, description=\"Year 2024\")\n",
    "\n",
    "print(f\"\\n✓ Created {G.slices.count()} slices\")\n",
    "print(f\"  slices: {G.slices.list()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e9d9289-b009-4395-85ac-3d44d9e596ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "slice 2022: Adding vertices\n",
      "============================================================\n",
      "\n",
      "✓ slice 2022:\n",
      "  Vertices: 4\n",
      "  Edges: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"slice 2022: Adding vertices\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "G.slices.active = \"2022\"\n",
    "\n",
    "# Add people\n",
    "people_2022 = {\n",
    "    \"alice\": {\"name\": \"Alice\", \"age\": 25, \"role\": \"engineer\", \"salary\": 80000},\n",
    "    \"bob\": {\"name\": \"Bob\", \"age\": 30, \"role\": \"manager\", \"salary\": 95000},\n",
    "    \"charlie\": {\"name\": \"Charlie\", \"age\": 28, \"role\": \"engineer\", \"salary\": 85000},\n",
    "    \"diana\": {\"name\": \"Diana\", \"age\": 35, \"role\": \"director\", \"salary\": 120000},\n",
    "}\n",
    "\n",
    "for vid, attrs in people_2022.items():\n",
    "    G.add_vertex(vid, **attrs)\n",
    "\n",
    "# Add collaborations (edges)\n",
    "collaborations_2022 = [\n",
    "    (\"alice\", \"bob\", 0.8, {\"project\": \"ProjectX\", \"hours\": 120}),\n",
    "    (\"alice\", \"charlie\", 0.9, {\"project\": \"ProjectX\", \"hours\": 150}),\n",
    "    (\"bob\", \"diana\", 0.7, {\"project\": \"Management\", \"hours\": 80}),\n",
    "    (\"charlie\", \"diana\", 0.6, {\"project\": \"ProjectY\", \"hours\": 60}),\n",
    "]\n",
    "\n",
    "for source, target, weight, attrs in collaborations_2022:\n",
    "    G.add_edge(source, target, weight=weight, **attrs)\n",
    "\n",
    "print(\"\\n✓ slice 2022:\")\n",
    "print(f\"  Vertices: {G.number_of_vertices()}\")\n",
    "print(f\"  Edges: {G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cd61063-777e-4d7d-9366-446ac1f6f487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "slice 2023: Adding vertices and edges\n",
      "============================================================\n",
      "\n",
      "✓ slice 2023:\n",
      "  Total vertices: 5\n",
      "  Edges in slice: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"slice 2023: Adding vertices and edges\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "G.slices.active = \"2023\"\n",
    "\n",
    "# Add existing people (some with updated attributes)\n",
    "people_2023 = {\n",
    "    \"alice\": {\"name\": \"Alice\", \"age\": 26, \"role\": \"senior_engineer\", \"salary\": 92000},\n",
    "    \"bob\": {\"name\": \"Bob\", \"age\": 31, \"role\": \"senior_manager\", \"salary\": 105000},\n",
    "    \"charlie\": {\"name\": \"Charlie\", \"age\": 29, \"role\": \"engineer\", \"salary\": 88000},\n",
    "    \"diana\": {\"name\": \"Diana\", \"age\": 36, \"role\": \"director\", \"salary\": 125000},\n",
    "    \"eve\": {\"name\": \"Eve\", \"age\": 27, \"role\": \"engineer\", \"salary\": 83000},  # New hire\n",
    "}\n",
    "\n",
    "for vid, attrs in people_2023.items():\n",
    "    if not G.has_vertex(vid):\n",
    "        G.add_vertex(vid, **attrs)\n",
    "\n",
    "# New collaborations\n",
    "collaborations_2023 = [\n",
    "    (\"alice\", \"bob\", 0.85, {\"project\": \"ProjectZ\", \"hours\": 140}),\n",
    "    (\"alice\", \"eve\", 0.95, {\"project\": \"ProjectZ\", \"hours\": 180}),  # New collaboration\n",
    "    (\"bob\", \"diana\", 0.75, {\"project\": \"Management\", \"hours\": 90}),\n",
    "    (\"charlie\", \"eve\", 0.8, {\"project\": \"ProjectW\", \"hours\": 100}),\n",
    "    (\"eve\", \"diana\", 0.7, {\"project\": \"ProjectW\", \"hours\": 70}),\n",
    "]\n",
    "\n",
    "for source, target, weight, attrs in collaborations_2023:\n",
    "    G.add_edge(source, target, weight=weight, **attrs)\n",
    "\n",
    "print(\"\\n✓ slice 2023:\")\n",
    "print(f\"  Total vertices: {G.number_of_vertices()}\")\n",
    "print(f'  Edges in slice: {len(G.slices.edges(\"2023\"))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ff21352-787c-4a4f-b2e9-069fe5286d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "slice 2024: Adding vertices and edges\n",
      "============================================================\n",
      "\n",
      "✓ slice 2024:\n",
      "  Total vertices: 6\n",
      "  Edges in slice: 5\n",
      "\n",
      "============================================================\n",
      "GRAPH SUMMARY\n",
      "============================================================\n",
      "Total unique vertices: 6\n",
      "Total unique edges: 14\n",
      "slices: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"slice 2024: Adding vertices and edges\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "G.slices.active = \"2024\"\n",
    "\n",
    "# 2024 people (Bob left, Frank joined)\n",
    "people_2024 = {\n",
    "    \"alice\": {\"name\": \"Alice\", \"age\": 27, \"role\": \"tech_lead\", \"salary\": 110000},\n",
    "    \"charlie\": {\"name\": \"Charlie\", \"age\": 30, \"role\": \"senior_engineer\", \"salary\": 98000},\n",
    "    \"diana\": {\"name\": \"Diana\", \"age\": 37, \"role\": \"vp\", \"salary\": 150000},\n",
    "    \"eve\": {\"name\": \"Eve\", \"age\": 28, \"role\": \"senior_engineer\", \"salary\": 95000},\n",
    "    \"frank\": {\"name\": \"Frank\", \"age\": 32, \"role\": \"manager\", \"salary\": 100000},  # Replaced Bob\n",
    "}\n",
    "\n",
    "for vid, attrs in people_2024.items():\n",
    "    if not G.has_vertex(vid):\n",
    "        G.add_vertex(vid, **attrs)\n",
    "\n",
    "# 2024 collaborations\n",
    "collaborations_2024 = [\n",
    "    (\"alice\", \"frank\", 0.9, {\"project\": \"NextGen\", \"hours\": 160}),\n",
    "    (\"alice\", \"eve\", 0.92, {\"project\": \"NextGen\", \"hours\": 170}),\n",
    "    (\"charlie\", \"eve\", 0.85, {\"project\": \"NextGen\", \"hours\": 120}),\n",
    "    (\"frank\", \"diana\", 0.8, {\"project\": \"Strategy\", \"hours\": 100}),\n",
    "    (\"eve\", \"diana\", 0.75, {\"project\": \"Strategy\", \"hours\": 80}),\n",
    "]\n",
    "\n",
    "for source, target, weight, attrs in collaborations_2024:\n",
    "    G.add_edge(source, target, weight=weight, **attrs)\n",
    "\n",
    "print(\"\\n✓ slice 2024:\")\n",
    "print(f\"  Total vertices: {G.number_of_vertices()}\")\n",
    "print(f'  Edges in slice: {len(G.slices.edges(\"2024\"))}')\n",
    "\n",
    "print(f'\\n{\"=\" * 60}')\n",
    "print(\"GRAPH SUMMARY\")\n",
    "print(f'{\"=\" * 60}')\n",
    "print(f\"Total unique vertices: {G.number_of_vertices()}\")\n",
    "print(f\"Total unique edges: {G.number_of_edges()}\")\n",
    "print(f\"slices: {G.slices.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c109bfa-0a46-4356-b12a-8d809c05a4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING ANNNET PROPERTIES\n",
      "============================================================\n",
      "\n",
      "1. obs (vertex attributes):\n",
      "shape: (6, 5)\n",
      "┌───────────┬─────────┬─────┬──────────┬────────┐\n",
      "│ vertex_id ┆ name    ┆ age ┆ role     ┆ salary │\n",
      "│ ---       ┆ ---     ┆ --- ┆ ---      ┆ ---    │\n",
      "│ str       ┆ str     ┆ i64 ┆ str      ┆ i64    │\n",
      "╞═══════════╪═════════╪═════╪══════════╪════════╡\n",
      "│ alice     ┆ Alice   ┆ 25  ┆ engineer ┆ 80000  │\n",
      "│ bob       ┆ Bob     ┆ 30  ┆ manager  ┆ 95000  │\n",
      "│ charlie   ┆ Charlie ┆ 28  ┆ engineer ┆ 85000  │\n",
      "│ diana     ┆ Diana   ┆ 35  ┆ director ┆ 120000 │\n",
      "│ eve       ┆ Eve     ┆ 27  ┆ engineer ┆ 83000  │\n",
      "│ frank     ┆ Frank   ┆ 32  ┆ manager  ┆ 100000 │\n",
      "└───────────┴─────────┴─────┴──────────┴────────┘\n",
      "\n",
      "   Shape: (6, 5)\n",
      "   Columns: ['vertex_id', 'name', 'age', 'role', 'salary']\n",
      "\n",
      "2. var (edge attributes):\n",
      "shape: (5, 3)\n",
      "┌─────────┬────────────┬───────┐\n",
      "│ edge_id ┆ project    ┆ hours │\n",
      "│ ---     ┆ ---        ┆ ---   │\n",
      "│ str     ┆ str        ┆ i64   │\n",
      "╞═════════╪════════════╪═══════╡\n",
      "│ edge_0  ┆ ProjectX   ┆ 120   │\n",
      "│ edge_1  ┆ ProjectX   ┆ 150   │\n",
      "│ edge_2  ┆ Management ┆ 80    │\n",
      "│ edge_3  ┆ ProjectY   ┆ 60    │\n",
      "│ edge_4  ┆ ProjectZ   ┆ 140   │\n",
      "└─────────┴────────────┴───────┘\n",
      "\n",
      "   Shape: (14, 3)\n",
      "   Columns: ['edge_id', 'project', 'hours']\n",
      "\n",
      "3. X (incidence matrix):\n",
      "   Type: <class 'scipy.sparse._dok.dok_matrix'>\n",
      "   Shape: (8, 16)\n",
      "   Non-zero entries: 28\n",
      "   Density: 0.2188\n",
      "\n",
      "4. uns (unstructured metadata):\n",
      "   {'dataset_name': 'Company Collaboration Network', 'created': '2025-12-02T16:40:13.813056', 'description': 'Multi-year collaboration network'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING ANNNET PROPERTIES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test obs (vertex attributes)\n",
    "print(\"\\n1. obs (vertex attributes):\")\n",
    "print(G.obs)\n",
    "print(f\"\\n   Shape: {G.obs.shape}\")\n",
    "print(f\"   Columns: {G.obs.columns}\")\n",
    "\n",
    "# Test var (edge attributes)\n",
    "print(\"\\n2. var (edge attributes):\")\n",
    "print(G.var.head())\n",
    "print(f\"\\n   Shape: {G.var.shape}\")\n",
    "print(f\"   Columns: {G.var.columns}\")\n",
    "\n",
    "# Test X (incidence matrix)\n",
    "print(\"\\n3. X (incidence matrix):\")\n",
    "X = G.X()\n",
    "print(f\"   Type: {type(X)}\")\n",
    "print(f\"   Shape: {X.shape}\")\n",
    "print(f\"   Non-zero entries: {X.nnz}\")\n",
    "print(f\"   Density: {X.nnz / (X.shape[0] * X.shape[1]):.4f}\")\n",
    "\n",
    "# Test uns (unstructured metadata)\n",
    "print(\"\\n4. uns (unstructured metadata):\")\n",
    "G.uns[\"dataset_name\"] = \"Company Collaboration Network\"\n",
    "G.uns[\"created\"] = datetime.now().isoformat()\n",
    "G.uns[\"description\"] = \"Multi-year collaboration network\"\n",
    "print(f\"   {G.uns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "430ae4a4-ca2c-4663-8725-bebbb066fe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING sliceMANAGER\n",
      "============================================================\n",
      "\n",
      "1. slice Info:\n",
      "   Active slice: 2024\n",
      "   All slices: ['2022', '2023', '2024']\n",
      "   slice count: 4\n",
      "\n",
      "2. slice Statistics:\n",
      "\n",
      "   2022:\n",
      "     Vertices: 4\n",
      "     Edges: 4\n",
      "     Attributes: {'year': 2022, 'description': 'Year 2022'}\n",
      "\n",
      "   2023:\n",
      "     Vertices: 5\n",
      "     Edges: 5\n",
      "     Attributes: {'year': 2023, 'description': 'Year 2023'}\n",
      "\n",
      "   2024:\n",
      "     Vertices: 5\n",
      "     Edges: 5\n",
      "     Attributes: {'year': 2024, 'description': 'Year 2024'}\n",
      "\n",
      "3. Union of 2022 and 2023:\n",
      "   Vertices: 5\n",
      "   Edges: 9\n",
      "   Vertex IDs: ['alice', 'bob', 'charlie', 'diana', 'eve']\n",
      "\n",
      "4. Intersection of 2022 and 2023:\n",
      "   Common vertices: ['alice', 'bob', 'charlie', 'diana']\n",
      "   Common edges: 0\n",
      "\n",
      "5. Create 'all_years' slice (union):\n",
      "   ✓ Created slice: all_years\n",
      "   Vertices: 6\n",
      "   Edges: 14\n",
      "\n",
      "6. slice Summary:\n",
      "slices: 5\n",
      "├─ default: 0 vertices, 0 edges\n",
      "├─ 2022: 4 vertices, 4 edges\n",
      "├─ 2023: 5 vertices, 5 edges\n",
      "├─ 2024: 5 vertices, 5 edges\n",
      "└─ all_years: 6 vertices, 14 edges\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING sliceMANAGER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Basic operations\n",
    "print(\"\\n1. slice Info:\")\n",
    "print(f\"   Active slice: {G.slices.active}\")\n",
    "print(f\"   All slices: {G.slices.list()}\")\n",
    "print(f\"   slice count: {G.slices.count()}\")\n",
    "\n",
    "# slice statistics\n",
    "print(\"\\n2. slice Statistics:\")\n",
    "stats = G.slices.stats()\n",
    "for slice_id, info in stats.items():\n",
    "    print(f\"\\n   {slice_id}:\")\n",
    "    print(f'     Vertices: {info[\"vertices\"]}')\n",
    "    print(f'     Edges: {info[\"edges\"]}')\n",
    "    print(f'     Attributes: {info[\"attributes\"]}')\n",
    "\n",
    "# slice operations - union\n",
    "print(\"\\n3. Union of 2022 and 2023:\")\n",
    "union_result = G.slices.union([\"2022\", \"2023\"])\n",
    "print(f'   Vertices: {len(union_result[\"vertices\"])}')\n",
    "print(f'   Edges: {len(union_result[\"edges\"])}')\n",
    "print(f'   Vertex IDs: {sorted(union_result[\"vertices\"])}')\n",
    "\n",
    "# slice operations - intersection\n",
    "print(\"\\n4. Intersection of 2022 and 2023:\")\n",
    "intersect_result = G.slices.intersect([\"2022\", \"2023\"])\n",
    "print(f'   Common vertices: {sorted(intersect_result[\"vertices\"])}')\n",
    "print(f'   Common edges: {len(intersect_result[\"edges\"])}')\n",
    "\n",
    "# Create aggregated slice\n",
    "print(\"\\n5. Create 'all_years' slice (union):\")\n",
    "G.slices.union_create([\"2022\", \"2023\", \"2024\"], \"all_years\", description=\"All years combined\")\n",
    "print(\"   ✓ Created slice: all_years\")\n",
    "print(f'   Vertices: {len(G.slices.vertices(\"all_years\"))}')\n",
    "print(f'   Edges: {len(G.slices.edges(\"all_years\"))}')\n",
    "\n",
    "# Summary\n",
    "print(\"\\n6. slice Summary:\")\n",
    "print(G.slices.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32da3ba8-b9eb-4776-a281-258ee295b583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING CROSS-slice ANALYTICS\n",
      "============================================================\n",
      "\n",
      "1. Vertex Presence Across slices:\n",
      "   alice: ['2022', '2023', '2024', 'all_years']\n",
      "   bob: ['2022', '2023', 'all_years']\n",
      "   eve: ['2023', '2024', 'all_years']\n",
      "   frank: ['2024', 'all_years']\n",
      "\n",
      "2. Edge Presence (alice→bob):\n",
      "   2022: ['edge_0']\n",
      "   2023: ['edge_4']\n",
      "   all_years: ['edge_0', 'edge_4']\n",
      "\n",
      "3. Conserved Edges (in 2+ slices):\n",
      "   Found 14 conserved edges:\n",
      "   edge_1: alice → charlie (in 2 slices)\n",
      "   edge_0: alice → bob (in 2 slices)\n",
      "   edge_2: bob → diana (in 2 slices)\n",
      "   edge_3: charlie → diana (in 2 slices)\n",
      "   edge_4: alice → bob (in 2 slices)\n",
      "\n",
      "4. slice-Specific Edges:\n",
      "   2022 only: 0 edges\n",
      "   2023 only: 0 edges\n",
      "   2024 only: 0 edges\n",
      "\n",
      "5. Temporal Dynamics:\n",
      "\n",
      "   2022 → 2023:\n",
      "     Edges added: 5\n",
      "     Edges removed: 4\n",
      "     Net change: +1\n",
      "\n",
      "   2023 → 2024:\n",
      "     Edges added: 5\n",
      "     Edges removed: 5\n",
      "     Net change: +0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING CROSS-slice ANALYTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Vertex presence\n",
    "print(\"\\n1. Vertex Presence Across slices:\")\n",
    "for vid in [\"alice\", \"bob\", \"eve\", \"frank\"]:\n",
    "    slices = G.slices.vertex_presence(vid)\n",
    "    print(f\"   {vid}: {slices}\")\n",
    "\n",
    "# Edge presence\n",
    "print(\"\\n2. Edge Presence (alice→bob):\")\n",
    "edge_presence = G.slices.edge_presence(source=\"alice\", target=\"bob\")\n",
    "for slice_id, edge_ids in edge_presence.items():\n",
    "    print(f\"   {slice_id}: {edge_ids}\")\n",
    "\n",
    "# Conserved edges\n",
    "print(\"\\n3. Conserved Edges (in 2+ slices):\")\n",
    "conserved = G.slices.conserved_edges(min_slices=2)\n",
    "print(f\"   Found {len(conserved)} conserved edges:\")\n",
    "for eid, count in sorted(conserved.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    edge_def = G.edge_definitions.get(eid)\n",
    "    if edge_def:\n",
    "        print(f\"   {eid}: {edge_def[0]} → {edge_def[1]} (in {count} slices)\")\n",
    "\n",
    "# slice-specific edges\n",
    "print(\"\\n4. slice-Specific Edges:\")\n",
    "for slice_id in [\"2022\", \"2023\", \"2024\"]:\n",
    "    specific = G.slices.specific_edges(slice_id)\n",
    "    print(f\"   {slice_id} only: {len(specific)} edges\")\n",
    "\n",
    "# Temporal dynamics\n",
    "print(\"\\n5. Temporal Dynamics:\")\n",
    "changes = G.slices.temporal_dynamics([\"2022\", \"2023\", \"2024\"], metric=\"edge_change\")\n",
    "for i, change in enumerate(changes):\n",
    "    year_from = [\"2022\", \"2023\"][i]\n",
    "    year_to = [\"2023\", \"2024\"][i]\n",
    "    print(f\"\\n   {year_from} → {year_to}:\")\n",
    "    print(f'     Edges added: {change[\"added\"]}')\n",
    "    print(f'     Edges removed: {change[\"removed\"]}')\n",
    "    print(f'     Net change: {change[\"net_change\"]:+d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b8cf64c-19f7-49ff-86d6-0c801ec9fad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING INDEXMANAGER\n",
      "============================================================\n",
      "\n",
      "1. Entity Index Lookups:\n",
      "   alice → row index: 0\n",
      "   diana → row index: 3\n",
      "   Row 0 → entity: alice\n",
      "   Row 3 → entity: diana\n",
      "\n",
      "2. Edge Index Lookups:\n",
      "   edge_0 → col 0 → edge_0\n",
      "   edge_1 → col 1 → edge_1\n",
      "   edge_2 → col 2 → edge_2\n",
      "\n",
      "3. Batch Lookups:\n",
      "   ['alice', 'bob', 'charlie']\n",
      "   → rows: [0, 1, 2]\n",
      "   → back: ['alice', 'bob', 'charlie']\n",
      "\n",
      "4. Existence Checks:\n",
      "   'alice' exists: True\n",
      "   'unknown' exists: False\n",
      "   edge count: 14\n",
      "   entity count: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING INDEXMANAGER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Entity lookups\n",
    "print(\"\\n1. Entity Index Lookups:\")\n",
    "print(f'   alice → row index: {G.idx.entity_to_row(\"alice\")}')\n",
    "print(f'   diana → row index: {G.idx.entity_to_row(\"diana\")}')\n",
    "print(f\"   Row 0 → entity: {G.idx.row_to_entity(0)}\")\n",
    "print(f\"   Row 3 → entity: {G.idx.row_to_entity(3)}\")\n",
    "\n",
    "# Edge lookups\n",
    "print(\"\\n2. Edge Index Lookups:\")\n",
    "edge_ids = list(G.edge_to_idx.keys())[:3]\n",
    "for eid in edge_ids:\n",
    "    col = G.idx.edge_to_col(eid)\n",
    "    back = G.idx.col_to_edge(col)\n",
    "    print(f\"   {eid} → col {col} → {back}\")\n",
    "\n",
    "# Batch lookups\n",
    "print(\"\\n3. Batch Lookups:\")\n",
    "vertices = [\"alice\", \"bob\", \"charlie\"]\n",
    "rows = G.idx.entities_to_rows(vertices)\n",
    "print(f\"   {vertices}\")\n",
    "print(f\"   → rows: {rows}\")\n",
    "back_entities = G.idx.rows_to_entities(rows)\n",
    "print(f\"   → back: {back_entities}\")\n",
    "\n",
    "# Check existence\n",
    "print(\"\\n4. Existence Checks:\")\n",
    "print(f\"   'alice' exists: {G.idx.has_entity('alice')}\")\n",
    "print(f\"   'unknown' exists: {G.idx.has_entity('unknown')}\")\n",
    "print(f\"   edge count: {G.idx.edge_count()}\")\n",
    "print(f\"   entity count: {G.idx.entity_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34c7cf69-a61d-4417-91b9-d535ddddcfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING CACHEMANAGER\n",
      "============================================================\n",
      "\n",
      "1. Initial Cache Status:\n",
      "   CSR cached: False\n",
      "   CSC cached: False\n",
      "\n",
      "2. Building CSR cache...\n",
      "   ✓ Built in 3.64ms\n",
      "   Shape: (8, 16)\n",
      "   Type: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "\n",
      "3. Building CSC cache...\n",
      "   ✓ Built in 0.28ms\n",
      "   Shape: (8, 16)\n",
      "\n",
      "4. Cache Hit Test:\n",
      "   ✓ Retrieved in 0.0226ms (cached)\n",
      "\n",
      "5. Clearing Cache:\n",
      "   CSR cached: False\n",
      "   CSC cached: False\n",
      "\n",
      "6. Rebuild All:\n",
      "   ✓ CSR cached: True\n",
      "   ✓ CSC cached: True\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING CACHEMANAGER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check cache status\n",
    "print(\"\\n1. Initial Cache Status:\")\n",
    "print(f\"   CSR cached: {G.cache.has_csr()}\")\n",
    "print(f\"   CSC cached: {G.cache.has_csc()}\")\n",
    "\n",
    "# Build CSR\n",
    "print(\"\\n2. Building CSR cache...\")\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "csr = G.cache.get_csr()\n",
    "t1 = time.time()\n",
    "print(f\"   ✓ Built in {(t1 - t0) * 1000:.2f}ms\")\n",
    "print(f\"   Shape: {csr.shape}\")\n",
    "print(f\"   Type: {type(csr)}\")\n",
    "\n",
    "# Build CSC\n",
    "print(\"\\n3. Building CSC cache...\")\n",
    "t0 = time.time()\n",
    "csc = G.cache.get_csc()\n",
    "t1 = time.time()\n",
    "print(f\"   ✓ Built in {(t1 - t0) * 1000:.2f}ms\")\n",
    "print(f\"   Shape: {csc.shape}\")\n",
    "\n",
    "# Check cache hit\n",
    "print(\"\\n4. Cache Hit Test:\")\n",
    "t0 = time.time()\n",
    "csr2 = G.cache.get_csr()  # Should be instant\n",
    "t1 = time.time()\n",
    "print(f\"   ✓ Retrieved in {(t1 - t0) * 1000:.4f}ms (cached)\")\n",
    "\n",
    "# Clear cache\n",
    "print(\"\\n5. Clearing Cache:\")\n",
    "G.cache.clear()\n",
    "print(f\"   CSR cached: {G.cache.has_csr()}\")\n",
    "print(f\"   CSC cached: {G.cache.has_csc()}\")\n",
    "\n",
    "# Rebuild\n",
    "print(\"\\n6. Rebuild All:\")\n",
    "G.cache.build()\n",
    "print(f\"   ✓ CSR cached: {G.cache.has_csr()}\")\n",
    "print(f\"   ✓ CSC cached: {G.cache.has_csc()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45dbdfcd-dbca-47ac-bf11-caa68408a76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING GRAPHVIEW - BASIC FILTERING\n",
      "============================================================\n",
      "\n",
      "1. View Specific vertices:\n",
      "   View: GraphView(vertices=3, edges=14)\n",
      "   vertices: 3\n",
      "   Edges: 14\n",
      "\n",
      "   vertex table:\n",
      "shape: (3, 5)\n",
      "┌───────────┬─────────┬─────┬──────────┬────────┐\n",
      "│ vertex_id ┆ name    ┆ age ┆ role     ┆ salary │\n",
      "│ ---       ┆ ---     ┆ --- ┆ ---      ┆ ---    │\n",
      "│ str       ┆ str     ┆ i64 ┆ str      ┆ i64    │\n",
      "╞═══════════╪═════════╪═════╪══════════╪════════╡\n",
      "│ alice     ┆ Alice   ┆ 25  ┆ engineer ┆ 80000  │\n",
      "│ bob       ┆ Bob     ┆ 30  ┆ manager  ┆ 95000  │\n",
      "│ charlie   ┆ Charlie ┆ 28  ┆ engineer ┆ 85000  │\n",
      "└───────────┴─────────┴─────┴──────────┴────────┘\n",
      "\n",
      "2. View slice 2023:\n",
      "   View: GraphView(vertices=5, edges=5)\n",
      "   vertices: 5\n",
      "   Edges: 5\n",
      "\n",
      "3. View slices 2022+2023:\n",
      "   View: GraphView(vertices=5, edges=9)\n",
      "   vertices: 5\n",
      "   Edges: 9\n",
      "\n",
      "4. Combined: Specific vertices in 2023:\n",
      "   View: GraphView(vertices=2, edges=1)\n",
      "   vertices: 2\n",
      "   Edges: 1\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING GRAPHVIEW - BASIC FILTERING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# View specific vertices\n",
    "print(\"\\n1. View Specific vertices:\")\n",
    "v = G.view(vertices=[\"alice\", \"bob\", \"charlie\"])\n",
    "print(f\"   View: {v}\")\n",
    "print(f\"   vertices: {v.vertex_count}\")\n",
    "print(f\"   Edges: {v.edge_count}\")\n",
    "print(\"\\n   vertex table:\")\n",
    "print(v.obs)\n",
    "\n",
    "# View specific slice\n",
    "print(\"\\n2. View slice 2023:\")\n",
    "v2023 = G.view(slices=\"2023\")\n",
    "print(f\"   View: {v2023}\")\n",
    "print(f\"   vertices: {v2023.vertex_count}\")\n",
    "print(f\"   Edges: {v2023.edge_count}\")\n",
    "\n",
    "# View multiple slices\n",
    "print(\"\\n3. View slices 2022+2023:\")\n",
    "v_early = G.view(slices=[\"2022\", \"2023\"])\n",
    "print(f\"   View: {v_early}\")\n",
    "print(f\"   vertices: {v_early.vertex_count}\")\n",
    "print(f\"   Edges: {v_early.edge_count}\")\n",
    "\n",
    "# Combined filters\n",
    "print(\"\\n4. Combined: Specific vertices in 2023:\")\n",
    "v_combo = G.view(vertices=[\"alice\", \"eve\"], slices=\"2023\")\n",
    "print(f\"   View: {v_combo}\")\n",
    "print(f\"   vertices: {v_combo.vertex_count}\")\n",
    "print(f\"   Edges: {v_combo.edge_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df08d37f-a217-424f-bfef-6e472ff55a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING GRAPHVIEW - PREDICATE FILTERING\n",
      "============================================================\n",
      "\n",
      "1. High Salary Employees (>100k):\n",
      "   View: GraphView(vertices=1, edges=14)\n",
      "   High earners: ['diana']\n",
      "\n",
      "   Details:\n",
      "shape: (1, 4)\n",
      "┌───────────┬───────┬────────┬──────────┐\n",
      "│ vertex_id ┆ name  ┆ salary ┆ role     │\n",
      "│ ---       ┆ ---   ┆ ---    ┆ ---      │\n",
      "│ str       ┆ str   ┆ i64    ┆ str      │\n",
      "╞═══════════╪═══════╪════════╪══════════╡\n",
      "│ diana     ┆ Diana ┆ 120000 ┆ director │\n",
      "└───────────┴───────┴────────┴──────────┘\n",
      "\n",
      "2. Strong Collaborations (weight > 0.8):\n",
      "   View: GraphView(vertices=6, edges=6)\n",
      "   Strong edges: 6\n",
      "\n",
      "   Top collaborations:\n",
      "shape: (6, 4)\n",
      "┌─────────┬─────────┬─────────┬───────────────┐\n",
      "│ edge_id ┆ source  ┆ target  ┆ global_weight │\n",
      "│ ---     ┆ ---     ┆ ---     ┆ ---           │\n",
      "│ str     ┆ str     ┆ str     ┆ f64           │\n",
      "╞═════════╪═════════╪═════════╪═══════════════╡\n",
      "│ edge_1  ┆ alice   ┆ charlie ┆ 0.9           │\n",
      "│ edge_4  ┆ alice   ┆ bob     ┆ 0.85          │\n",
      "│ edge_5  ┆ alice   ┆ eve     ┆ 0.95          │\n",
      "│ edge_9  ┆ alice   ┆ frank   ┆ 0.9           │\n",
      "│ edge_10 ┆ alice   ┆ eve     ┆ 0.92          │\n",
      "│ edge_11 ┆ charlie ┆ eve     ┆ 0.85          │\n",
      "└─────────┴─────────┴─────────┴───────────────┘\n",
      "\n",
      "3. Engineers in 2023/2024:\n",
      "   View: GraphView(vertices=3, edges=4)\n",
      "   Engineers: ['alice', 'charlie', 'eve']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING GRAPHVIEW - PREDICATE FILTERING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# View by vertex predicate (high salary)\n",
    "print(\"\\n1. High Salary Employees (>100k):\")\n",
    "v_rich = G.view(vertices=lambda vid: G.get_vertex_attrs(vid).get(\"salary\", 0) > 100000)\n",
    "print(f\"   View: {v_rich}\")\n",
    "print(f\"   High earners: {sorted(v_rich.vertex_ids)}\")\n",
    "print(\"\\n   Details:\")\n",
    "print(v_rich.obs.select([\"vertex_id\", \"name\", \"salary\", \"role\"]))\n",
    "\n",
    "# View by edge predicate (strong collaboration)\n",
    "print(\"\\n2. Strong Collaborations (weight > 0.8):\")\n",
    "v_strong = G.view(edges=lambda eid: G.edge_weights.get(eid, 0) > 0.8)\n",
    "print(f\"   View: {v_strong}\")\n",
    "print(f\"   Strong edges: {v_strong.edge_count}\")\n",
    "edges_df = v_strong.edges_df(include_weight=True)\n",
    "print(\"\\n   Top collaborations:\")\n",
    "print(edges_df.select([\"edge_id\", \"source\", \"target\", \"global_weight\"]).head(10))\n",
    "\n",
    "# Combined predicate (engineers in recent years)\n",
    "print(\"\\n3. Engineers in 2023/2024:\")\n",
    "v_eng = G.view(\n",
    "    vertices=lambda vid: \"engineer\" in G.get_vertex_attrs(vid).get(\"role\", \"\"), slices=[\"2023\", \"2024\"]\n",
    ")\n",
    "print(f\"   View: {v_eng}\")\n",
    "print(f\"   Engineers: {sorted(v_eng.vertex_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a000bf8-6d8c-4c5a-9b4d-0b7eb180878e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING GRAPHVIEW - ADVANCED OPERATIONS\n",
      "============================================================\n",
      "\n",
      "1. View Properties:\n",
      "   vertex_count: 5\n",
      "   edge_count: 5\n",
      "   vertex_ids: ['alice', 'bob', 'charlie', 'diana', 'eve']\n",
      "\n",
      "   Matrix shape: (5, 5)\n",
      "   Matrix nnz: 10\n",
      "\n",
      "2. View DataFrames:\n",
      "   Vertices DF: (5, 5)\n",
      "   Edges DF: (5, 13)\n",
      "\n",
      "3. View Summary:\n",
      "GraphView Summary\n",
      "──────────────────────────────\n",
      "vertices: 5\n",
      "Edges: 5\n",
      "Filters: slices=['2023']\n",
      "\n",
      "4. Nested Views:\n",
      "   v1 (2023): 5 vertices, 5 edges\n",
      "   v2 (alice/bob/eve in 2023): 3 vertices, 2 edges\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING GRAPHVIEW - ADVANCED OPERATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Access properties\n",
    "print(\"\\n1. View Properties:\")\n",
    "v = G.view(slices=\"2023\")\n",
    "print(f\"   vertex_count: {v.vertex_count}\")\n",
    "print(f\"   edge_count: {v.edge_count}\")\n",
    "print(f\"   vertex_ids: {sorted(list(v.vertex_ids))}\")\n",
    "print(f\"\\n   Matrix shape: {v.X.shape}\")\n",
    "print(f\"   Matrix nnz: {v.X.nnz}\")\n",
    "\n",
    "# Get DataFrames\n",
    "print(\"\\n2. View DataFrames:\")\n",
    "vertices_df = v.vertices_df()\n",
    "edges_df = v.edges_df(include_weight=True, include_directed=True)\n",
    "print(f\"   Vertices DF: {vertices_df.shape}\")\n",
    "print(f\"   Edges DF: {edges_df.shape}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n3. View Summary:\")\n",
    "print(v.summary())\n",
    "\n",
    "# Nested views\n",
    "print(\"\\n4. Nested Views:\")\n",
    "v1 = G.view(slices=\"2023\")\n",
    "print(f\"   v1 (2023): {v1.vertex_count} vertices, {v1.edge_count} edges\")\n",
    "\n",
    "v2 = v1.subview(vertices=[\"alice\", \"bob\", \"eve\"])\n",
    "print(f\"   v2 (alice/bob/eve in 2023): {v2.vertex_count} vertices, {v2.edge_count} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "218b98dd-cea1-4c5c-a221-330690f05a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING GRAPHVIEW - MATERIALIZATION\n",
      "============================================================\n",
      "\n",
      "1. Materialize slice 2023:\n",
      "   Original graph: 6 vertices, 14 edges\n",
      "   Subgraph 2023: 5 vertices, 5 edges\n",
      "   Subgraph vertices: ['alice', 'bob', 'charlie', 'diana', 'eve']\n",
      "\n",
      "   Sample attributes:\n",
      "   alice: {'vertex_id': 'alice', 'name': 'Alice', 'age': 25, 'role': 'engineer', 'salary': 80000}\n",
      "\n",
      "2. Materialize High Earners Network:\n",
      "   High earners network: 2 vertices\n",
      "   vertices: ['diana', 'frank']\n",
      "   Edges: 1\n",
      "\n",
      "3. Verify Independence:\n",
      "   Original graph edges: 14\n",
      "   Subgraph edges: 5\n",
      "   After modifying subgraph:\n",
      "     Original: 6 vertices\n",
      "     Subgraph: 6 vertices\n",
      "   ✓ Graphs are independent\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING GRAPHVIEW - MATERIALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Materialize slice 2023\n",
    "print(\"\\n1. Materialize slice 2023:\")\n",
    "v2023 = G.view(slices=\"2023\")\n",
    "subG = v2023.materialize(copy_attributes=True)\n",
    "\n",
    "print(f\"   Original graph: {G.number_of_vertices()} vertices, {G.number_of_edges()} edges\")\n",
    "print(f\"   Subgraph 2023: {subG.number_of_vertices()} vertices, {subG.number_of_edges()} edges\")\n",
    "print(f\"   Subgraph vertices: {sorted(subG.vertices())}\")\n",
    "\n",
    "# Check attributes were copied\n",
    "print(\"\\n   Sample attributes:\")\n",
    "alice_attrs = subG.get_vertex_attrs(\"alice\")\n",
    "print(f\"   alice: {alice_attrs}\")\n",
    "\n",
    "# Materialize high earners\n",
    "print(\"\\n2. Materialize High Earners Network:\")\n",
    "v_rich = G.view(vertices=lambda vid: G.get_vertex_attrs(vid).get(\"salary\", 0) > 95000)\n",
    "rich_network = v_rich.materialize(copy_attributes=True)\n",
    "\n",
    "print(f\"   High earners network: {rich_network.number_of_vertices()} vertices\")\n",
    "print(f\"   vertices: {sorted(rich_network.vertices())}\")\n",
    "print(f\"   Edges: {rich_network.number_of_edges()}\")\n",
    "\n",
    "# Verify independence\n",
    "print(\"\\n3. Verify Independence:\")\n",
    "print(f\"   Original graph edges: {G.number_of_edges()}\")\n",
    "print(f\"   Subgraph edges: {subG.number_of_edges()}\")\n",
    "subG.add_vertex(\"test_vertex\")\n",
    "print(\"   After modifying subgraph:\")\n",
    "print(f\"     Original: {G.number_of_vertices()} vertices\")\n",
    "print(f\"     Subgraph: {subG.number_of_vertices()} vertices\")\n",
    "print(\"   ✓ Graphs are independent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc68b9ad-2209-4274-a97f-d67cc0507234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING SNAPSHOT AND DIFF\n",
      "============================================================\n",
      "\n",
      "1. Create Initial Snapshot:\n",
      "   ✓ Created snapshot: initial_state\n",
      "   Vertices: 6\n",
      "   Edges: 14\n",
      "   slices: 5\n",
      "\n",
      "2. Make Changes:\n",
      "   Adding new vertices...\n",
      "   Adding new edges...\n",
      "   Removing a vertex...\n",
      "\n",
      "   ✓ Created snapshot: after_changes\n",
      "\n",
      "3. Compare Snapshots:\n",
      "Diff: initial_state - after_changes\n",
      "\n",
      "Vertices: +2 added, 1 removed\n",
      "Edges: +2 added, 2 removed\n",
      "slices: +0 added, 0 removed\n",
      "\n",
      "   Details:\n",
      "   Added vertices: ['grace', 'henry']\n",
      "   Removed vertices: ['frank']\n",
      "   Added edges: 2\n",
      "   Removed edges: 2\n",
      "\n",
      "4. Compare with Current State:\n",
      "Diff: after_changes - current\n",
      "\n",
      "Vertices: +1 added, 0 removed\n",
      "Edges: +0 added, 0 removed\n",
      "slices: +0 added, 0 removed\n",
      "\n",
      "5. List All Snapshots:\n",
      "\n",
      "   initial_state:\n",
      "     Timestamp: 2025-12-02T15:40:16.385370+00:00\n",
      "     Vertices: 6\n",
      "     Edges: 14\n",
      "\n",
      "   after_changes:\n",
      "     Timestamp: 2025-12-02T15:40:16.396745+00:00\n",
      "     Vertices: 7\n",
      "     Edges: 14\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING SNAPSHOT AND DIFF\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create initial snapshot\n",
    "print(\"\\n1. Create Initial Snapshot:\")\n",
    "G.slices.active = \"2024\"\n",
    "snap1 = G.snapshot(\"initial_state\")\n",
    "print(f'   ✓ Created snapshot: {snap1[\"label\"]}')\n",
    "print(f'   Vertices: {snap1[\"counts\"][\"vertices\"]}')\n",
    "print(f'   Edges: {snap1[\"counts\"][\"edges\"]}')\n",
    "print(f'   slices: {snap1[\"counts\"][\"slices\"]}')\n",
    "\n",
    "# Make changes\n",
    "print(\"\\n2. Make Changes:\")\n",
    "print(\"   Adding new vertices...\")\n",
    "G.add_vertex(\"grace\", name=\"Grace\", age=29, role=\"engineer\", salary=87000)\n",
    "G.add_vertex(\"henry\", name=\"Henry\", age=33, role=\"architect\", salary=115000)\n",
    "\n",
    "print(\"   Adding new edges...\")\n",
    "G.add_edge(\"grace\", \"alice\", weight=0.85, project=\"Innovation\")\n",
    "G.add_edge(\"henry\", \"diana\", weight=0.9, project=\"Architecture\")\n",
    "\n",
    "print(\"   Removing a vertex...\")\n",
    "G.remove_vertex(\"frank\")\n",
    "\n",
    "# Create second snapshot\n",
    "snap2 = G.snapshot(\"after_changes\")\n",
    "print(f'\\n   ✓ Created snapshot: {snap2[\"label\"]}')\n",
    "\n",
    "# Diff\n",
    "print(\"\\n3. Compare Snapshots:\")\n",
    "diff = G.diff(\"initial_state\", \"after_changes\")\n",
    "print(diff.summary())\n",
    "\n",
    "print(\"\\n   Details:\")\n",
    "print(f\"   Added vertices: {sorted(diff.vertices_added)}\")\n",
    "print(f\"   Removed vertices: {sorted(diff.vertices_removed)}\")\n",
    "print(f\"   Added edges: {len(diff.edges_added)}\")\n",
    "print(f\"   Removed edges: {len(diff.edges_removed)}\")\n",
    "\n",
    "# Compare with current\n",
    "print(\"\\n4. Compare with Current State:\")\n",
    "G.add_vertex(\"iris\", name=\"Iris\", age=26, role=\"data_scientist\", salary=92000)\n",
    "diff_current = G.diff(\"after_changes\")\n",
    "print(diff_current.summary())\n",
    "\n",
    "# List all snapshots\n",
    "print(\"\\n5. List All Snapshots:\")\n",
    "snapshots = G.list_snapshots()\n",
    "for snap in snapshots:\n",
    "    print(f'\\n   {snap[\"label\"]}:')\n",
    "    print(f'     Timestamp: {snap[\"timestamp\"]}')\n",
    "    print(f'     Vertices: {snap[\"counts\"][\"vertices\"]}')\n",
    "    print(f'     Edges: {snap[\"counts\"][\"edges\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef810453-37cc-406c-bdf2-8d555058bd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ADVANCED ANALYSIS - NETWORK METRICS\n",
      "============================================================\n",
      "\n",
      "1. Per-slice Network Metrics:\n",
      "\n",
      "   2022:\n",
      "     vertices: 4\n",
      "     Edges: 4\n",
      "     Avg edge weight: 0.000\n",
      "     Avg degree: 2.00\n",
      "     Max degree: 2\n",
      "     Hub: charlie (degree=2)\n",
      "\n",
      "   2023:\n",
      "     vertices: 5\n",
      "     Edges: 5\n",
      "     Avg edge weight: 0.000\n",
      "     Avg degree: 2.00\n",
      "     Max degree: 3\n",
      "     Hub: eve (degree=3)\n",
      "\n",
      "   2024:\n",
      "     vertices: 7\n",
      "     Edges: 5\n",
      "     Avg edge weight: 0.000\n",
      "     Avg degree: 1.43\n",
      "     Max degree: 3\n",
      "     Hub: eve (degree=3)\n",
      "\n",
      "2. slice Comparison:\n",
      "\n",
      "   Vertex changes over time:\n",
      "   2022→2023: +1 added, 0 removed\n",
      "   2023→2024: +3 added, 1 removed\n",
      "\n",
      "   Edge changes over time:\n",
      "   2022→2023: +5 added, 4 removed\n",
      "   2023→2024: +5 added, 5 removed\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ADVANCED ANALYSIS - NETWORK METRICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Per-slice analysis\n",
    "print(\"\\n1. Per-slice Network Metrics:\")\n",
    "for slice_id in [\"2022\", \"2023\", \"2024\"]:\n",
    "    v = G.view(slices=slice_id)\n",
    "\n",
    "    print(f\"\\n   {slice_id}:\")\n",
    "    print(f\"     vertices: {v.vertex_count}\")\n",
    "    print(f\"     Edges: {v.edge_count}\")\n",
    "\n",
    "    if v.edge_count > 0:\n",
    "        avg_weight = v.var.select(\"weight\").mean().item() if \"weight\" in v.var.columns else 0\n",
    "        print(f\"     Avg edge weight: {avg_weight:.3f}\")\n",
    "\n",
    "    # Degree analysis (using materialized subgraph)\n",
    "    subG = v.materialize()\n",
    "    degrees = {vid: subG.degree(vid) for vid in subG.vertices()}\n",
    "    if degrees:\n",
    "        print(f\"     Avg degree: {sum(degrees.values()) / len(degrees):.2f}\")\n",
    "        print(f\"     Max degree: {max(degrees.values())}\")\n",
    "        max_degree_vertex = max(degrees, key=degrees.get)\n",
    "        print(f\"     Hub: {max_degree_vertex} (degree={degrees[max_degree_vertex]})\")\n",
    "\n",
    "# Compare slices\n",
    "print(\"\\n2. slice Comparison:\")\n",
    "changes = G.slices.temporal_dynamics([\"2022\", \"2023\", \"2024\"], metric=\"vertex_change\")\n",
    "print(\"\\n   Vertex changes over time:\")\n",
    "for i, change in enumerate(changes):\n",
    "    year_from = [\"2022\", \"2023\"][i]\n",
    "    year_to = [\"2023\", \"2024\"][i]\n",
    "    print(f'   {year_from}→{year_to}: {change[\"added\"]:+d} added, {change[\"removed\"]} removed')\n",
    "\n",
    "changes = G.slices.temporal_dynamics([\"2022\", \"2023\", \"2024\"], metric=\"edge_change\")\n",
    "print(\"\\n   Edge changes over time:\")\n",
    "for i, change in enumerate(changes):\n",
    "    year_from = [\"2022\", \"2023\"][i]\n",
    "    year_to = [\"2023\", \"2024\"][i]\n",
    "    print(f'   {year_from}→{year_to}: {change[\"added\"]:+d} added, {change[\"removed\"]} removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c919cbe-3201-422e-b96a-c92332c41b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ADVANCED ANALYSIS - POLARS QUERIES\n",
      "============================================================\n",
      "\n",
      "1. Top 3 Earners:\n",
      "shape: (3, 4)\n",
      "┌───────────┬───────┬───────────┬────────┐\n",
      "│ vertex_id ┆ name  ┆ role      ┆ salary │\n",
      "│ ---       ┆ ---   ┆ ---       ┆ ---    │\n",
      "│ str       ┆ str   ┆ str       ┆ i64    │\n",
      "╞═══════════╪═══════╪═══════════╪════════╡\n",
      "│ diana     ┆ Diana ┆ director  ┆ 120000 │\n",
      "│ henry     ┆ Henry ┆ architect ┆ 115000 │\n",
      "│ bob       ┆ Bob   ┆ manager   ┆ 95000  │\n",
      "└───────────┴───────┴───────────┴────────┘\n",
      "\n",
      "2. Role Distribution:\n",
      "shape: (5, 3)\n",
      "┌────────────────┬───────┬────────────┐\n",
      "│ role           ┆ count ┆ avg_salary │\n",
      "│ ---            ┆ ---   ┆ ---        │\n",
      "│ str            ┆ u32   ┆ f64        │\n",
      "╞════════════════╪═══════╪════════════╡\n",
      "│ engineer       ┆ 4     ┆ 83750.0    │\n",
      "│ director       ┆ 1     ┆ 120000.0   │\n",
      "│ data_scientist ┆ 1     ┆ 92000.0    │\n",
      "│ architect      ┆ 1     ┆ 115000.0   │\n",
      "│ manager        ┆ 1     ┆ 95000.0    │\n",
      "└────────────────┴───────┴────────────┘\n",
      "\n",
      "3. Top 5 Collaborations by Weight:\n",
      "shape: (5, 2)\n",
      "┌─────────┬──────────────────┐\n",
      "│ edge_id ┆ effective_weight │\n",
      "│ ---     ┆ ---              │\n",
      "│ str     ┆ f64              │\n",
      "╞═════════╪══════════════════╡\n",
      "│ edge_5  ┆ 0.95             │\n",
      "│ edge_4  ┆ 0.85             │\n",
      "│ edge_7  ┆ 0.8              │\n",
      "│ edge_6  ┆ 0.75             │\n",
      "│ edge_8  ┆ 0.7              │\n",
      "└─────────┴──────────────────┘\n",
      "\n",
      "4. Total Hours by Project:\n",
      "shape: (9, 3)\n",
      "┌──────────────┬────────────────┬─────────────┐\n",
      "│ project      ┆ collaborations ┆ total_hours │\n",
      "│ ---          ┆ ---            ┆ ---         │\n",
      "│ str          ┆ u32            ┆ i64         │\n",
      "╞══════════════╪════════════════╪═════════════╡\n",
      "│ ProjectZ     ┆ 2              ┆ 320         │\n",
      "│ NextGen      ┆ 2              ┆ 290         │\n",
      "│ ProjectX     ┆ 2              ┆ 270         │\n",
      "│ Management   ┆ 2              ┆ 170         │\n",
      "│ ProjectW     ┆ 2              ┆ 170         │\n",
      "│ Strategy     ┆ 1              ┆ 80          │\n",
      "│ ProjectY     ┆ 1              ┆ 60          │\n",
      "│ Architecture ┆ 1              ┆ 0           │\n",
      "│ Innovation   ┆ 1              ┆ 0           │\n",
      "└──────────────┴────────────────┴─────────────┘\n",
      "\n",
      "5. Salary Statistics:\n",
      "shape: (1, 4)\n",
      "┌────────────┬────────────┬────────────┬───────────────┐\n",
      "│ min_salary ┆ max_salary ┆ avg_salary ┆ median_salary │\n",
      "│ ---        ┆ ---        ┆ ---        ┆ ---           │\n",
      "│ i64        ┆ i64        ┆ f64        ┆ f64           │\n",
      "╞════════════╪════════════╪════════════╪═══════════════╡\n",
      "│ 80000      ┆ 120000     ┆ 94625.0    ┆ 89500.0       │\n",
      "└────────────┴────────────┴────────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ADVANCED ANALYSIS - POLARS QUERIES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Query 1: Top earners\n",
    "print(\"\\n1. Top 3 Earners:\")\n",
    "top_earners = G.obs.sort(\"salary\", descending=True).head(3)\n",
    "print(top_earners.select([\"vertex_id\", \"name\", \"role\", \"salary\"]))\n",
    "\n",
    "# Query 2: Role distribution\n",
    "print(\"\\n2. Role Distribution:\")\n",
    "role_dist = (\n",
    "    G.obs.group_by(\"role\")\n",
    "    .agg([pl.count(\"vertex_id\").alias(\"count\"), pl.mean(\"salary\").alias(\"avg_salary\")])\n",
    "    .sort(\"count\", descending=True)\n",
    ")\n",
    "print(role_dist)\n",
    "\n",
    "# Query 3: High-weight collaborations\n",
    "print(\"\\n3. Top 5 Collaborations by Weight:\")\n",
    "top_edges = (\n",
    "    G.view(slices=\"2023\")\n",
    "    .edges_df(\n",
    "        slice=\"2023\", include_weight=True, resolved_weight=True\n",
    "    )  # adds global_weight, slice_weight, effective_weight\n",
    "    .sort(\"effective_weight\", descending=True)\n",
    "    .select([\"edge_id\", \"effective_weight\"])\n",
    "    .head(5)\n",
    ")\n",
    "print(top_edges)\n",
    "\n",
    "# Query 4: Projects by hours\n",
    "print(\"\\n4. Total Hours by Project:\")\n",
    "if \"project\" in G.var.columns and \"hours\" in G.var.columns:\n",
    "    project_hours = (\n",
    "        G.var.group_by(\"project\")\n",
    "        .agg([pl.count(\"edge_id\").alias(\"collaborations\"), pl.sum(\"hours\").alias(\"total_hours\")])\n",
    "        .sort(\"total_hours\", descending=True)\n",
    "    )\n",
    "    print(project_hours)\n",
    "\n",
    "# Query 5: Salary growth (across snapshots if attributes updated)\n",
    "print(\"\\n5. Salary Statistics:\")\n",
    "salary_stats = G.obs.select(\n",
    "    [\n",
    "        pl.col(\"salary\").min().alias(\"min_salary\"),\n",
    "        pl.col(\"salary\").max().alias(\"max_salary\"),\n",
    "        pl.col(\"salary\").mean().alias(\"avg_salary\"),\n",
    "        pl.col(\"salary\").median().alias(\"median_salary\"),\n",
    "    ]\n",
    ")\n",
    "print(salary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be06eac8-c889-4ec4-87dc-6e5bd0e23660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PERFORMANCE BENCHMARKS\n",
      "============================================================\n",
      "\n",
      "1. View Creation (1000 iterations):\n",
      "   Time: 0.34ms total (0.0003ms per view)\n",
      "\n",
      "2. Property Access (1000 iterations):\n",
      "   Time: 3209.94ms total\n",
      "\n",
      "3. Materialization (100 iterations):\n",
      "   Time: 77.03ms total (0.77ms per materialization)\n",
      "\n",
      "4. Snapshot Creation (100 iterations):\n",
      "   Time: 0.69ms total (0.01ms per snapshot)\n",
      "   Total snapshots: 102\n",
      "\n",
      "5. DataFrame Filtering (1000 iterations):\n",
      "   Time: 1295.99ms total (1.2960ms per filter)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PERFORMANCE BENCHMARKS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import time\n",
    "\n",
    "# Benchmark 1: View creation\n",
    "print(\"\\n1. View Creation (1000 iterations):\")\n",
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    v = G.view(slices=\"2023\")\n",
    "t1 = time.time()\n",
    "print(f\"   Time: {(t1 - t0) * 1000:.2f}ms total ({(t1 - t0):.4f}ms per view)\")\n",
    "\n",
    "# Benchmark 2: Property access\n",
    "print(\"\\n2. Property Access (1000 iterations):\")\n",
    "v = G.view(slices=\"2023\")\n",
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    _ = v.obs\n",
    "    _ = v.var\n",
    "t1 = time.time()\n",
    "print(f\"   Time: {(t1 - t0) * 1000:.2f}ms total\")\n",
    "\n",
    "# Benchmark 3: Materialization\n",
    "print(\"\\n3. Materialization (100 iterations):\")\n",
    "v = G.view(slices=\"2023\")\n",
    "t0 = time.time()\n",
    "for _ in range(100):\n",
    "    subG = v.materialize(copy_attributes=False)\n",
    "t1 = time.time()\n",
    "print(f\"   Time: {(t1 - t0) * 1000:.2f}ms total ({(t1 - t0) * 10:.2f}ms per materialization)\")\n",
    "\n",
    "# Benchmark 4: Snapshot creation\n",
    "print(\"\\n4. Snapshot Creation (100 iterations):\")\n",
    "t0 = time.time()\n",
    "for i in range(100):\n",
    "    G.snapshot(f\"bench_{i}\")\n",
    "t1 = time.time()\n",
    "print(f\"   Time: {(t1 - t0) * 1000:.2f}ms total ({(t1 - t0) * 10:.2f}ms per snapshot)\")\n",
    "print(f\"   Total snapshots: {len(G._snapshots)}\")\n",
    "\n",
    "# Benchmark 5: DataFrame filtering\n",
    "print(\"\\n5. DataFrame Filtering (1000 iterations):\")\n",
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    filtered = G.obs.filter(pl.col(\"salary\") > 90000)\n",
    "t1 = time.time()\n",
    "print(f\"   Time: {(t1 - t0) * 1000:.2f}ms total ({(t1 - t0):.4f}ms per filter)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "787e7c7a-a887-4338-9c55-08f68f10f45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ANNNET COMPLETE TEST SUMMARY\n",
      "============================================================\n",
      "\n",
      "📊 GRAPH STATISTICS\n",
      "   Vertices: 8\n",
      "   Edges: 14\n",
      "   slices: 5\n",
      "   Snapshots: 102\n",
      "\n",
      "✅ TESTED FEATURES\n",
      "    1. AnnNet Properties (X, obs, var, uns)\n",
      "    2. sliceManager (add, remove, union, intersect, stats)\n",
      "    3. IndexManager (entity/edge lookups)\n",
      "    4. CacheManager (CSR/CSC caching)\n",
      "    5. GraphView (filtering, predicates, materialization)\n",
      "    6. Snapshot & Diff (versioning, comparison)\n",
      "    7. I/O (save/load .annnet format)\n",
      "    8. Cross-slice analytics\n",
      "    9. Polars integration\n",
      "   10. Performance benchmarks\n",
      "\n",
      "📈 slice DETAILS\n",
      "slices: 5\n",
      "├─ default: 0 vertices, 0 edges\n",
      "├─ 2022: 4 vertices, 4 edges\n",
      "├─ 2023: 5 vertices, 5 edges\n",
      "├─ 2024: 7 vertices, 5 edges\n",
      "└─ all_years: 5 vertices, 12 edges\n",
      "\n",
      "🎯 RECOMMENDATIONS\n",
      "   1. Use views for large subgraph operations (lazy, efficient)\n",
      "   2. Create snapshots before major graph modifications\n",
      "   3. Use slices for temporal/contextual data organization\n",
      "   4. Leverage Polars for fast attribute queries\n",
      "   5. Cache CSR/CSC for repeated matrix operations\n",
      "\n",
      "============================================================\n",
      "✓ ALL TESTS COMPLETED SUCCESSFULLY!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ANNNET COMPLETE TEST SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n📊 GRAPH STATISTICS\")\n",
    "print(f\"   Vertices: {G.number_of_vertices()}\")\n",
    "print(f\"   Edges: {G.number_of_edges()}\")\n",
    "print(f\"   slices: {G.slices.count()}\")\n",
    "print(f\"   Snapshots: {len(G._snapshots)}\")\n",
    "\n",
    "print(\"\\n✅ TESTED FEATURES\")\n",
    "features = [\n",
    "    \"AnnNet Properties (X, obs, var, uns)\",\n",
    "    \"sliceManager (add, remove, union, intersect, stats)\",\n",
    "    \"IndexManager (entity/edge lookups)\",\n",
    "    \"CacheManager (CSR/CSC caching)\",\n",
    "    \"GraphView (filtering, predicates, materialization)\",\n",
    "    \"Snapshot & Diff (versioning, comparison)\",\n",
    "    \"I/O (save/load .annnet format)\",\n",
    "    \"Cross-slice analytics\",\n",
    "    \"Polars integration\",\n",
    "    \"Performance benchmarks\",\n",
    "]\n",
    "\n",
    "for i, feature in enumerate(features, 1):\n",
    "    print(f\"   {i:2d}. {feature}\")\n",
    "\n",
    "print(\"\\n📈 slice DETAILS\")\n",
    "print(G.slices.summary())\n",
    "\n",
    "print(\"\\n🎯 RECOMMENDATIONS\")\n",
    "print(\"   1. Use views for large subgraph operations (lazy, efficient)\")\n",
    "print(\"   2. Create snapshots before major graph modifications\")\n",
    "print(\"   3. Use slices for temporal/contextual data organization\")\n",
    "print(\"   4. Leverage Polars for fast attribute queries\")\n",
    "print(\"   5. Cache CSR/CSC for repeated matrix operations\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"✓ ALL TESTS COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8ec23b-5a63-4ffa-9368-4fdee91eb9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc27eb4-a6dd-4117-b537-65d694a8b4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb75e00-0d0f-4993-8d26-eb39298c2256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8048ad30-5a41-4da6-930f-8a33d7406921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59e5072-b4c8-4d0f-b83d-4b90b4af6513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c735c089-c6de-4662-aa64-1696488fee4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1dec90-abed-452c-baeb-15a5cba86914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c04929a-cc40-409c-ab55-45a16f999a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed57a81-b9ac-41e6-ad06-4f4c1bfef34f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd253c-7239-4632-a044-97f7bd955fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c8ab58-38cf-44a5-b2e5-ee3ad2ba5e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce02eb8-8338-4c1a-b38e-de09ba0602c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d59067e-bd7e-415e-a264-b84a3502fa59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08740914-5083-4565-bfe6-c82daddd8427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98b76c7-94e2-40de-bcd7-664c3b2014c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af994dd-a27d-4eee-a421-ad4e0170be63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b6ffb5-48eb-486a-b95f-e7fa9cb48fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b42a4d-1c67-4566-8c40-503c19d3fbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9336f9-59b1-4465-9662-3a2d4022466d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d793b4-1449-49d9-ac5c-9e7a3b73398c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dec03fd-d97d-4840-aa0e-a62fbea76dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
